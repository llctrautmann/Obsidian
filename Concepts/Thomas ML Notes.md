---
title: Thomas ML Notes
date:
  - 30-04-2024
time: 19:19
author: Luca Trautmann
tags: 
series: experimental
chapter: 
status: Incomplete
modified: 2024-05-03
---
# Thomas ML Notes

> [!PDF|yellow] [[@Thomas2018.pdf#page=1&selection=11,0,11,64&color=yellow|@Thomas2018, p.1]]
> > Machine learning uses tools from a variety of mathematical fields

Chief among the Calculus, [[Linear Algebra]] and [[Probability Theory Definitions]]. 

> [!PDF|yellow] [[@Thomas2018.pdf#page=6&selection=15,55,31,0&color=yellow|@Thomas2018, p.6]]
> > A vector space V is a set (the elements of which are called vectors) on which two operations are defined: vectors can be added together, and vectors can be multiplied by real numbers1 called scalars.


Vector spaces have have two main conditions (addition and multiplication) and six additional constrains. 

> [!PDF|yellow] [[@Thomas2018.pdf#page=7&selection=71,0,73,0&color=yellow|@Thomas2018, p.7]]
> > Euclidean space is used to mathematically represent physical space, with notions such as distance, length, and angles.

Thinking in 3D is probably always ok, even when working in higher dimensional space.


> [!PDF|yellow] [[@Thomas2018.pdf#page=9&selection=151,0,159,2&color=yellow|@Thomas2018, p.9]]
> > It is a remarkable fact that the dimension of the columnspace of A is the same as the dimension of the rowspace of A. 

`This is so fucking sick!`

> [!PDF|yellow] [[@Thomas2018.pdf#page=9&selection=329,0,329,59&color=red|@Thomas2018, p.9]]
> > Norms generalize the notion of length from Euclidean space.
> 
> Norms are cool, Linear Algebra is cool, I am cool. 

> [!PDF|yellow] [[@Thomas2018.pdf#page=10&selection=53,1,70,2&color=yellow|@Thomas2018, p.10]]
> > $x, y ∈ V$ and all $α ∈ R$. 
> 
> it is also possible to extract latex but things need to be latexed 



> [!PDF|yellow] [[@Thomas2018.pdf#page=15&selection=344,0,348,54&color=yellow|@Thomas2018, p.15]]
> > The trace of a square matrix is the sum of its diagonal entries:
> 
> Very useful property `here and here`




