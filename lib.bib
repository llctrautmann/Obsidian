@article{aalaei2023,
  title = {Architectural Layout Generation Using a Graph-Constrained Conditional {{Generative Adversarial Network}} ({{GAN}})},
  author = {Aalaei, Mohammadreza and Saadi, Melika and Rahbar, Morteza and Ekhlassi, Ahmad},
  date = {2023-11},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  volume = {155},
  pages = {105053},
  issn = {09265805},
  doi = {10.1016/j.autcon.2023.105053},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0926580523003138},
  urldate = {2023-09-23},
  langid = {english},
  file = {/Users/luca/Documents/literature/zotero/aalaei2023.pdf}
}

@article{abdar2021,
  title = {A Review of Uncertainty Quantification in Deep Learning: {{Techniques}}, Applications and Challenges},
  shorttitle = {A Review of Uncertainty Quantification in Deep Learning},
  author = {Abdar, Moloud and Pourpanah, Farhad and Hussain, Sadiq and Rezazadegan, Dana and Liu, Li and Ghavamzadeh, Mohammad and Fieguth, Paul and Cao, Xiaochun and Khosravi, Abbas and Acharya, U. Rajendra and Makarenkov, Vladimir and Nahavandi, Saeid},
  date = {2021-12},
  journaltitle = {Information Fusion},
  shortjournal = {Information Fusion},
  volume = {76},
  pages = {243--297},
  issn = {15662535},
  doi = {10.1016/j.inffus.2021.05.008},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1566253521001081},
  urldate = {2023-10-26},
  langid = {english},
  keywords = {in progress},
  file = {/Users/luca/Documents/literature/zotero/abdar2021.pdf}
}

@inproceedings{abdelaziz2015,
  title = {Uncertainty Propagation through Deep Neural Networks},
  booktitle = {Interspeech 2015},
  author = {Abdelaziz, Ahmed Hussen and Watanabe, Shinji and Hershey, John R. and Vincent, Emmanuel and Kolossa, Dorothea},
  date = {2015-09-06},
  pages = {3561--3565},
  publisher = {ISCA},
  doi = {10.21437/Interspeech.2015-706},
  url = {https://www.isca-speech.org/archive/interspeech_2015/abdelaziz15_interspeech.html},
  urldate = {2023-11-29},
  eventtitle = {Interspeech 2015},
  langid = {english},
  keywords = {new},
  file = {/Users/luca/Documents/literature/zotero/abdelaziz2015.pdf}
}

@article{aggarwal2017,
  title = {{{MoDL}}: {{Model Based Deep Learning Architecture}} for {{Inverse Problems}}},
  shorttitle = {{{MoDL}}},
  author = {Aggarwal, Hemant Kumar and Mani, Merry P. and Jacob, Mathews},
  date = {2017},
  publisher = {[object Object]},
  doi = {10.48550/ARXIV.1712.02862},
  url = {https://arxiv.org/abs/1712.02862},
  urldate = {2024-03-11},
  abstract = {We introduce a model-based image reconstruction framework with a convolution neural network (CNN) based regularization prior. The proposed formulation provides a systematic approach for deriving deep architectures for inverse problems with the arbitrary structure. Since the forward model is explicitly accounted for, a smaller network with fewer parameters is sufficient to capture the image information compared to black-box deep learning approaches, thus reducing the demand for training data and training time. Since we rely on end-to-end training, the CNN weights are customized to the forward model, thus offering improved performance over approaches that rely on pre-trained denoisers. The main difference of the framework from existing end-to-end training strategies is the sharing of the network weights across iterations and channels. Our experiments show that the decoupling of the number of iterations from the network complexity offered by this approach provides benefits including lower demand for training data, reduced risk of overfitting, and implementations with significantly reduced memory footprint. We propose to enforce data-consistency by using numerical optimization blocks such as conjugate gradients algorithm within the network; this approach offers faster convergence per iteration, compared to methods that rely on proximal gradients steps to enforce data consistency. Our experiments show that the faster convergence translates to improved performance, especially when the available GPU memory restricts the number of iterations.},
  version = {4},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences},
  file = {/Users/luca/Documents/literature/zotero/aggarwal2017.pdf}
}

@article{alaifari2021,
  title = {Gabor Phase Retrieval Is Severely Ill-Posed},
  author = {Alaifari, Rima and Grohs, Philipp},
  date = {2021-01},
  journaltitle = {Applied and Computational Harmonic Analysis},
  shortjournal = {Applied and Computational Harmonic Analysis},
  volume = {50},
  pages = {401--419},
  issn = {10635203},
  doi = {10.1016/j.acha.2019.09.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1063520318301404},
  urldate = {2024-01-08},
  langid = {english},
  keywords = {read},
  file = {/Users/luca/Documents/literature/zotero/alaifari2021.pdf}
}

@article{arkov2022,
  title = {Uncertainty {{Estimation}} in {{Machine Learning}}},
  author = {Arkov, Valentin},
  date = {2022},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2206.01749},
  url = {https://arxiv.org/abs/2206.01749},
  urldate = {2023-08-14},
  abstract = {Most machine learning techniques are based upon statistical learning theory, often simplified for the sake of computing speed. This paper is focused on the uncertainty aspect of mathematical modeling in machine learning. Regression analysis is chosen to further investigate the evaluation aspect of uncertainty in model coefficients and, more importantly, in the output feature value predictions. A survey demonstrates major stages in the conventional least squares approach to the creation of the regression model, along with its uncertainty estimation. On the other hand, it is shown that in machine learning the model complexity and severe nonlinearity become serious obstacles to uncertainty evaluation. Furthermore, the process of machine model training demands high computing power, not available at the level of personal computers. This is why so-called pre-trained models are widely used in such areas of machine learning as natural language processing. The latest example of a pre-trained model is the Generative Pre-trained Transformer 3 with hundreds of billions of parameters and a half-terabyte training dataset. Similarly, mathematical models built from real data are growing in complexity which is accompanied by the growing amount of training data. However, when machine models and their predictions are used in decision-making, one needs to estimate uncertainty and evaluate accompanying risks. This problem could be resolved with non-parametric techniques at the expense of greater demand for computing power, which can be offered by modern supercomputers available, including those utilizing graphical and tensor processing units along with the conventional central processors.},
  version = {1},
  keywords = {60H99,Artificial Intelligence (cs.AI),I.2.6,in progress,Machine Learning (cs.LG)},
  file = {/Users/luca/Documents/literature/zotero/arkov2022.pdf}
}

@article{auger2012,
  title = {On {{Phase-Magnitude Relationships}} in the {{Short-Time Fourier Transform}}},
  author = {Auger, François and Chassande-Mottin, Éric and Flandrin, Patrick},
  date = {2012-05},
  journaltitle = {IEEE Signal Processing Letters},
  shortjournal = {IEEE Signal Process. Lett.},
  volume = {19},
  number = {5},
  pages = {267--270},
  issn = {1070-9908, 1558-2361},
  doi = {10.1109/LSP.2012.2190279},
  url = {http://ieeexplore.ieee.org/document/6165644/},
  urldate = {2023-08-30},
  file = {/Users/luca/Documents/literature/zotero/auger2012.pdf}
}

@book{axler2024,
  title = {Linear Algebra Done Right},
  author = {Axler, Sheldon Jay},
  date = {2024},
  edition = {Fourth edition},
  publisher = {Springer},
  location = {Cham},
  abstract = {Now available in Open Access, this best-selling textbook for a second course in linear algebra is aimed at undergraduate math majors and graduate students. The fourth edition gives an expanded treatment of the singular value decomposition and its consequences. It includes a new chapter on multilinear algebra, treating bilinear forms, quadratic forms, tensor products, and an approach to determinants via alternating multilinear forms. This new edition also increases the use of the minimal polynomial to provide cleaner proofs of multiple results. Also, over 250 new exercises have been added. The novel approach taken here banishes determinants to the end of the book. The text focuses on the central goal of linear algebra: understanding the structure of linear operators on finite-dimensional vector spaces. The author has taken unusual care to motivate concepts and simplify proofs. A variety of interesting exercises in each chapter helps students understand and manipulate the objects of linear algebra. Beautiful formatting creates pages with an unusually student-friendly appearance in both print and electronic versions. No prerequisites are assumed other than the usual demand for suitable mathematical maturity. The text starts by discussing vector spaces, linear independence, span, basis, and dimension. The book then deals with linear maps, eigenvalues, and eigenvectors. Inner-product spaces are introduced, leading to the finite-dimensional spectral theorem and its consequences. Generalized eigenvectors are then used to provide insight into the structure of a linear operator},
  isbn = {978-3-031-41026-0},
  langid = {english},
  keywords = {new},
  annotation = {OCLC: 1406837723},
  file = {/Users/luca/Documents/literature/zotero/axler2024.pdf}
}

@article{balestriero2023,
  title = {A {{Cookbook}} of {{Self-Supervised Learning}}},
  author = {Balestriero, Randall and Ibrahim, Mark and Sobal, Vlad and Morcos, Ari and Shekhar, Shashank and Goldstein, Tom and Bordes, Florian and Bardes, Adrien and Mialon, Gregoire and Tian, Yuandong and Schwarzschild, Avi and Wilson, Andrew Gordon and Geiping, Jonas and Garrido, Quentin and Fernandez, Pierre and Bar, Amir and Pirsiavash, Hamed and LeCun, Yann and Goldblum, Micah},
  date = {2023},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2304.12210},
  url = {https://arxiv.org/abs/2304.12210},
  urldate = {2023-05-15},
  abstract = {Self-supervised learning, dubbed the dark matter of intelligence, is a promising path to advance machine learning. Yet, much like cooking, training SSL methods is a delicate art with a high barrier to entry. While many components are familiar, successfully training a SSL method involves a dizzying set of choices from the pretext tasks to training hyper-parameters. Our goal is to lower the barrier to entry into SSL research by laying the foundations and latest SSL recipes in the style of a cookbook. We hope to empower the curious researcher to navigate the terrain of methods, understand the role of the various knobs, and gain the know-how required to explore how delicious SSL can be.},
  version = {1},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),Machine Learning (cs.LG),new},
  file = {/Users/luca/Documents/literature/zotero/balestriero2023.pdf}
}

@article{barber2019,
  title = {The Limits of Distribution-Free Conditional Predictive Inference},
  author = {Barber, Rina Foygel and Candès, Emmanuel J. and Ramdas, Aaditya and Tibshirani, Ryan J.},
  date = {2019},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1903.04684},
  url = {https://arxiv.org/abs/1903.04684},
  urldate = {2023-10-25},
  abstract = {We consider the problem of distribution-free predictive inference, with the goal of producing predictive coverage guarantees that hold conditionally rather than marginally. Existing methods such as conformal prediction offer marginal coverage guarantees, where predictive coverage holds on average over all possible test points, but this is not sufficient for many practical applications where we would like to know that our predictions are valid for a given individual, not merely on average over a population. On the other hand, exact conditional inference guarantees are known to be impossible without imposing assumptions on the underlying distribution. In this work we aim to explore the space in between these two, and examine what types of relaxations of the conditional coverage property would alleviate some of the practical concerns with marginal coverage guarantees while still being possible to achieve in a distribution-free setting.},
  version = {2},
  keywords = {FOS: Mathematics,new,Statistics Theory (math.ST)},
  file = {/Users/luca/Documents/literature/zotero/barber2019.pdf}
}

@article{bengio2012,
  title = {Practical Recommendations for Gradient-Based Training of Deep Architectures},
  author = {Bengio, Yoshua},
  date = {2012},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1206.5533},
  url = {https://arxiv.org/abs/1206.5533},
  urldate = {2023-05-11},
  abstract = {Learning algorithms related to artificial neural networks and in particular for Deep Learning may seem to involve many bells and whistles, called hyper-parameters. This chapter is meant as a practical guide with recommendations for some of the most commonly used hyper-parameters, in particular in the context of learning algorithms based on back-propagated gradient and gradient-based optimization. It also discusses how to deal with the fact that more interesting results can be obtained when allowing one to adjust many hyper-parameters. Overall, it describes elements of the practice used to successfully and efficiently train and debug large-scale and often deep multi-layer neural networks. It closes with open questions about the training difficulties observed with deeper architectures.},
  version = {2},
  keywords = {Machine Learning (cs.LG),new},
  file = {/Users/luca/Documents/literature/zotero/bengio2012.pdf}
}

@article{berger2002,
  title = {How Does It Work?: {{Magnetic}} Resonance Imaging},
  shorttitle = {How Does It Work?},
  author = {Berger, A.},
  date = {2002-01-05},
  journaltitle = {BMJ},
  shortjournal = {BMJ},
  volume = {324},
  number = {7328},
  pages = {35--35},
  issn = {0959-8138, 1468-5833},
  doi = {10.1136/bmj.324.7328.35},
  url = {https://www.bmj.com/lookup/doi/10.1136/bmj.324.7328.35},
  urldate = {2023-10-23},
  langid = {english},
  keywords = {read},
  file = {/Users/luca/Documents/literature/zotero/berger2002.pdf}
}

@article{bianco2019,
  title = {Machine Learning in Acoustics: {{Theory}} and Applications},
  shorttitle = {Machine Learning in Acoustics},
  author = {Bianco, Michael J. and Gerstoft, Peter and Traer, James and Ozanich, Emma and Roch, Marie A. and Gannot, Sharon and Deledalle, Charles-Alban},
  date = {2019-11-01},
  journaltitle = {The Journal of the Acoustical Society of America},
  volume = {146},
  number = {5},
  pages = {3590--3628},
  issn = {0001-4966, 1520-8524},
  doi = {10.1121/1.5133944},
  url = {https://pubs.aip.org/jasa/article/146/5/3590/994832/Machine-learning-in-acoustics-Theory-and},
  urldate = {2023-09-27},
  abstract = {Acoustic data provide scientific and engineering insights in fields ranging from biology and communications to ocean and Earth science. We survey the recent advances and transformative potential of machine learning (ML), including deep learning, in the field of acoustics. ML is a broad family of techniques, which are often based in statistics, for automatically detecting and utilizing patterns in data. Relative to conventional acoustics and signal processing, ML is data-driven. Given sufficient training data, ML can discover complex relationships between features and desired labels or actions, or between features themselves. With large volumes of training data, ML can discover models describing complex acoustic phenomena such as human speech and reverberation. ML in acoustics is rapidly developing with compelling results and significant future promise. We first introduce ML, then highlight ML developments in four acoustics research areas: source localization in speech processing, source localization in ocean acoustics, bioacoustics, and environmental sounds in everyday scenes.},
  langid = {english},
  file = {/Users/luca/Documents/literature/zotero/bianco2019.pdf;/Users/luca/Documents/literature/zotero/bianco22.pdf}
}

@article{blei2017,
  title = {Variational {{Inference}}: {{A Review}} for {{Statisticians}}},
  shorttitle = {Variational {{Inference}}},
  author = {Blei, David M. and Kucukelbir, Alp and McAuliffe, Jon D.},
  date = {2017-04-03},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  volume = {112},
  number = {518},
  pages = {859--877},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2017.1285773},
  url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1285773},
  urldate = {2023-05-19},
  langid = {english},
  keywords = {new},
  file = {/Users/luca/Documents/literature/zotero/blei2017.pdf}
}

@article{blundell2015,
  title = {Weight {{Uncertainty}} in {{Neural Networks}}},
  author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
  date = {2015},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1505.05424},
  url = {https://arxiv.org/abs/1505.05424},
  urldate = {2023-10-31},
  abstract = {We introduce a new, efficient, principled and backpropagation-compatible algorithm for learning a probability distribution on the weights of a neural network, called Bayes by Backprop. It regularises the weights by minimising a compression cost, known as the variational free energy or the expected lower bound on the marginal likelihood. We show that this principled kind of regularisation yields comparable performance to dropout on MNIST classification. We then demonstrate how the learnt uncertainty in the weights can be used to improve generalisation in non-linear regression problems, and how this weight uncertainty can be used to drive the exploration-exploitation trade-off in reinforcement learning.},
  version = {2},
  keywords = {FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML),new},
  file = {/Users/luca/Documents/literature/zotero/blundell2015.pdf}
}

@article{bowman2015,
  title = {Generating {{Sentences}} from a {{Continuous Space}}},
  author = {Bowman, Samuel R. and Vilnis, Luke and Vinyals, Oriol and Dai, Andrew M. and Jozefowicz, Rafal and Bengio, Samy},
  date = {2015},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1511.06349},
  url = {https://arxiv.org/abs/1511.06349},
  urldate = {2023-07-03},
  abstract = {The standard recurrent neural network language model (RNNLM) generates sentences one word at a time and does not work from an explicit global sentence representation. In this work, we introduce and study an RNN-based variational autoencoder generative model that incorporates distributed latent representations of entire sentences. This factorization allows it to explicitly model holistic properties of sentences such as style, topic, and high-level syntactic features. Samples from the prior over these sentence representations remarkably produce diverse and well-formed sentences through simple deterministic decoding. By examining paths through this latent space, we are able to generate coherent novel sentences that interpolate between known sentences. We present techniques for solving the difficult learning problem presented by this model, demonstrate its effectiveness in imputing missing words, explore many interesting properties of the model's latent sentence space, and present negative results on the use of the model in language modeling.},
  version = {4},
  keywords = {Computation and Language (cs.CL),in progress,Machine Learning (cs.LG)},
  file = {/Users/luca/Documents/literature/zotero/bowman2015.pdf}
}

@article{bronstein2021,
  title = {Geometric {{Deep Learning}}: {{Grids}}, {{Groups}}, {{Graphs}}, {{Geodesics}}, and {{Gauges}}},
  shorttitle = {Geometric {{Deep Learning}}},
  author = {Bronstein, Michael M. and Bruna, Joan and Cohen, Taco and Veličković, Petar},
  date = {2021},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2104.13478},
  url = {https://arxiv.org/abs/2104.13478},
  urldate = {2023-07-04},
  abstract = {The last decade has witnessed an experimental revolution in data science and machine learning, epitomised by deep learning methods. Indeed, many high-dimensional learning tasks previously thought to be beyond reach -- such as computer vision, playing Go, or protein folding -- are in fact feasible with appropriate computational scale. Remarkably, the essence of deep learning is built from two simple algorithmic principles: first, the notion of representation or feature learning, whereby adapted, often hierarchical, features capture the appropriate notion of regularity for each task, and second, learning by local gradient-descent type methods, typically implemented as backpropagation. While learning generic functions in high dimensions is a cursed estimation problem, most tasks of interest are not generic, and come with essential pre-defined regularities arising from the underlying low-dimensionality and structure of the physical world. This text is concerned with exposing these regularities through unified geometric principles that can be applied throughout a wide spectrum of applications. Such a 'geometric unification' endeavour, in the spirit of Felix Klein's Erlangen Program, serves a dual purpose: on one hand, it provides a common mathematical framework to study the most successful neural network architectures, such as CNNs, RNNs, GNNs, and Transformers. On the other hand, it gives a constructive procedure to incorporate prior physical knowledge into neural architectures and provide principled way to build future architectures yet to be invented.},
  version = {2},
  keywords = {Artificial Intelligence (cs.AI),Computational Geometry (cs.CG),Computer Vision and Pattern Recognition (cs.CV),in progress,Machine Learning (cs.LG),Machine Learning (stat.ML)},
  file = {/Users/luca/Documents/literature/zotero/bronstein2021.pdf}
}

@book{brooks2011,
  title = {Handbook of {{Markov}} Chain {{Monte Carlo}}},
  editor = {Brooks, Steve},
  date = {2011},
  publisher = {CRC Press},
  location = {Boca Raton},
  abstract = {Since their popularization in the 1990s, Markov chain Monte Carlo (MCMC) methods have revolutionized statistical computing and have had an especially profound impact on the practice of Bayesian statistics. Furthermore, MCMC methods have enabled the development and use of intricate models in an astonishing array of disciplines as diverse as fisheries science and economics. The wide-ranging practical importance of MCMC has sparked an expansive and deep investigation into fundamental Markov chain theory.The Handbook of Markov Chain Monte Carlo provides a referenc},
  isbn = {978-1-4200-7942-5},
  langid = {english},
  keywords = {new},
  annotation = {OCLC: 740896891},
  file = {/Users/luca/Documents/literature/zotero/brooks2011.pdf}
}

@book{brualdi2010,
  title = {Introductory Combinatorics},
  author = {Brualdi, Richard A.},
  date = {2010},
  edition = {5th ed},
  publisher = {Pearson/Prentice Hall},
  location = {Upper Saddle River, N.J},
  abstract = {Introductory Combinatorics emphasizes combinatorial ideas, including the pigeon-hole principle, counting techniques, permutations and combinations, Polya counting, binomial coefficients, inclusion-exclusion principle, generating functions and recurrence relations, and combinatortial structures (matchings, designs, graphs). Written to be entertaining and readable, this book's lively style reflects the author's joy for teaching the subject. It presents an excellent treatment of Polya's Counting Theorem that doesn't assume the student is familiar with group theory. It also includes problems that offer good practice of the principles it presents. The third edition of Introductory Combinatorics has been updated to include new material on partially ordered sets, Dilworth's Theorem, partitions of integers and generating functions. In addition, the chapters on graph theory have been completely revised. A valuable book for any reader interested in learning more about combinatorics},
  isbn = {978-0-13-602040-0},
  langid = {english},
  pagetotal = {605},
  file = {/Users/luca/Documents/literature/zotero/brualdi2010.pdf}
}

@article{burt2020,
  title = {Generative Modeling of Brain Maps with Spatial Autocorrelation},
  author = {Burt, Joshua B. and Helmer, Markus and Shinn, Maxwell and Anticevic, Alan and Murray, John D.},
  date = {2020-10},
  journaltitle = {NeuroImage},
  shortjournal = {NeuroImage},
  volume = {220},
  pages = {117038},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2020.117038},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811920305243},
  urldate = {2023-11-01},
  langid = {english},
  keywords = {new},
  file = {/Users/luca/Documents/literature/zotero/burt2020.pdf}
}

@book{chan2023,
  title = {Introduction to Probability for Data Science},
  editora = {Chan, Stanley H.},
  editoratype = {collaborator},
  date = {2023},
  publisher = {Michigan Publishing},
  location = {Ann Arbor, MI},
  isbn = {978-1-60785-746-4},
  langid = {english},
  keywords = {in progress},
  annotation = {OCLC: 1385298830},
  file = {/Users/luca/Documents/literature/zotero/chan2023.pdf;/Users/luca/Documents/literature/zotero/chan22.pdf}
}

@book{cummings2021,
  title = {Real Analysis: A Long-Form Mathematics Textbook},
  shorttitle = {Real Analysis},
  author = {Cummings, Jay},
  date = {2021},
  edition = {Second edition},
  publisher = {LongFormMath.com},
  location = {Sacramento, CA},
  abstract = {"Rather than the typical definition-theorem-proof-repeat style, this text includes much more commentary, motivation and explanation. The proofs are not terse, and aim for understanding over economy. Furthermore, dozens of proofs are preceded by 'scratch work' or a proof sketch to give students a big-picture view and an explanation of how they would come up with it on their own. Examples often drive the narrative and challenge the intuition of the reader."--Page 4 of cover},
  isbn = {978-1-07-725454-1},
  langid = {english},
  pagetotal = {431}
}

@article{davidson2018,
  title = {Hyperspherical {{Variational Auto-Encoders}}},
  author = {Davidson, Tim R. and Falorsi, Luca and De Cao, Nicola and Kipf, Thomas and Tomczak, Jakub M.},
  date = {2018},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1804.00891},
  url = {https://arxiv.org/abs/1804.00891},
  urldate = {2023-05-23},
  abstract = {The Variational Auto-Encoder (VAE) is one of the most used unsupervised machine learning models. But although the default choice of a Gaussian distribution for both the prior and posterior represents a mathematically convenient distribution often leading to competitive results, we show that this parameterization fails to model data with a latent hyperspherical structure. To address this issue we propose using a von Mises-Fisher (vMF) distribution instead, leading to a hyperspherical latent space. Through a series of experiments we show how such a hyperspherical VAE, or \$\textbackslash mathcal\{S\}\$-VAE, is more suitable for capturing data with a hyperspherical latent structure, while outperforming a normal, \$\textbackslash mathcal\{N\}\$-VAE, in low dimensions on other data types. Code at http://github.com/nicola-decao/s-vae-tf and https://github.com/nicola-decao/s-vae-pytorch},
  version = {3},
  keywords = {Machine Learning (cs.LG),Machine Learning (stat.ML),new},
  file = {/Users/luca/Documents/literature/zotero/davidson2018.pdf}
}

@article{dehghan2022,
  title = {Applications of Machine Learning to Behavioral Sciences: Focus on Categorical Data},
  shorttitle = {Applications of Machine Learning to Behavioral Sciences},
  author = {Dehghan, Pegah and Alashwal, Hany and Moustafa, Ahmed A.},
  date = {2022-12},
  journaltitle = {Discover Psychology},
  shortjournal = {Discov Psychol},
  volume = {2},
  number = {1},
  pages = {22},
  issn = {2731-4537},
  doi = {10.1007/s44202-022-00027-5},
  url = {https://link.springer.com/10.1007/s44202-022-00027-5},
  urldate = {2023-05-06},
  abstract = {Abstract             In the last two decades, advancements in artificial intelligence and data science have attracted researchers' attention to machine learning. Growing interests in applying machine learning algorithms can be observed in different scientific areas, including behavioral sciences. However, most of the research conducted in this area applied machine learning algorithms to imagining and physiological data such as EEG and fMRI and there are relatively limited non-imaging and non-physiological behavioral studies which have used machine learning to analyze their data. Therefore, in this perspective article, we aim to (1) provide a general understanding of models built for inference, models built for prediction (i.e., machine learning), methods used in these models, and their strengths and limitations; (2) investigate the applications of machine learning to categorical data in behavioral sciences; and (3) highlight the usefulness of applying machine learning algorithms to non-imaging and non-physiological data (e.g., clinical and categorical) data and provide evidence to encourage researchers to conduct further machine learning studies in behavioral and clinical sciences.},
  langid = {english},
  keywords = {new},
  file = {/Users/luca/Documents/literature/zotero/dehghan2022.pdf}
}

@book{deisenroth2020,
  title = {Mathematics for Machine Learning},
  author = {Deisenroth, Marc Peter and Faisal, A. Aldo and Ong, Cheng Soon},
  date = {2020},
  publisher = {Cambridge University Press},
  location = {Cambridge ; New York, NY},
  abstract = {"The fundamental mathematical tools needed to understand machine learning include linear algebra, analytic geometry, matrix decompositions, vector calculus, optimization, probability, and statistics. These topics are traditionally taught in disparate courses, making it hard for data science or computer science students, or professionals, to efficiently learn the mathematics. This self-contained textbook bridges the gap between mathematical and machine learning texts, introducing the mathematical concepts with a minimum of prerequisites. It uses these concepts to derive four central machine learning methods: linear regression, principal component analysis, Gaussian mixture models, and support vector machines. For students and others with a mathematical background, these derivations provide a starting point to machine learning texts. For those learning the mathematics for the first time, the methods help build intuition and practical experience with applying mathematical concepts"--},
  isbn = {978-1-108-47004-9 978-1-108-45514-5},
  keywords = {in progress,Machine learning,Mathematics},
  file = {/Users/luca/Documents/literature/zotero/deisenroth2020.pdf}
}

@article{deleeuwdenbouter2022,
  title = {Deep Learning-Based Single Image Super-Resolution for Low-Field {{MR}} Brain Images},
  author = {De Leeuw Den Bouter, M. L. and Ippolito, G. and O’Reilly, T. P. A. and Remis, R. F. and Van Gijzen, M. B. and Webb, A. G.},
  date = {2022-04-16},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {12},
  number = {1},
  pages = {6362},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-10298-6},
  url = {https://www.nature.com/articles/s41598-022-10298-6},
  urldate = {2023-11-29},
  abstract = {Abstract             Low-field MRI scanners are significantly less expensive than their high-field counterparts, which gives them the potential to make MRI technology more accessible all around the world. In general, images acquired using low-field MRI scanners tend to be of a relatively low resolution, as signal-to-noise ratios are lower. The aim of this work is to improve the resolution of these images. To this end, we present a deep learning-based approach to transform low-resolution low-field MR images into high-resolution ones. A convolutional neural network was trained to carry out single image super-resolution reconstruction using pairs of noisy low-resolution images and their noise-free high-resolution counterparts, which were obtained from the publicly available NYU fastMRI database. This network was subsequently applied to noisy images acquired using a low-field MRI scanner. The trained convolutional network yielded sharp super-resolution images in which most of the high-frequency components were recovered. In conclusion, we showed that a deep learning-based approach has great potential when it comes to increasing the resolution of low-field MR images.},
  langid = {english},
  keywords = {read,reviewed},
  file = {/Users/luca/Documents/literature/zotero/deleeuwdenbouter2022.pdf}
}

@article{doersch2016,
  title = {Tutorial on {{Variational Autoencoders}}},
  author = {Doersch, Carl},
  date = {2016},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1606.05908},
  url = {https://arxiv.org/abs/1606.05908},
  urldate = {2023-05-23},
  abstract = {In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, CIFAR images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
  version = {3},
  keywords = {in progress,Machine Learning (cs.LG),Machine Learning (stat.ML)},
  file = {/Users/luca/Documents/literature/zotero/doersch2016.pdf}
}

@article{dong2016,
  title = {Accelerating the {{Super-Resolution Convolutional Neural Network}}},
  author = {Dong, Chao and Loy, Chen Change and Tang, Xiaoou},
  date = {2016},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1608.00367},
  url = {https://arxiv.org/abs/1608.00367},
  urldate = {2023-11-30},
  abstract = {As a successful deep model applied in image super-resolution (SR), the Super-Resolution Convolutional Neural Network (SRCNN) has demonstrated superior performance to the previous hand-crafted models either in speed and restoration quality. However, the high computational cost still hinders it from practical usage that demands real-time performance (24 fps). In this paper, we aim at accelerating the current SRCNN, and propose a compact hourglass-shape CNN structure for faster and better SR. We re-design the SRCNN structure mainly in three aspects. First, we introduce a deconvolution layer at the end of the network, then the mapping is learned directly from the original low-resolution image (without interpolation) to the high-resolution one. Second, we reformulate the mapping layer by shrinking the input feature dimension before mapping and expanding back afterwards. Third, we adopt smaller filter sizes but more mapping layers. The proposed model achieves a speed up of more than 40 times with even superior restoration quality. Further, we present the parameter settings that can achieve real-time performance on a generic CPU while still maintaining good performance. A corresponding transfer strategy is also proposed for fast training and testing across different upscaling factors.},
  version = {1},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,new},
  file = {/Users/luca/Documents/literature/zotero/dong2016.pdf}
}

@article{edupuganti2019,
  title = {Uncertainty {{Quantification}} in {{Deep MRI Reconstruction}}},
  author = {Edupuganti, Vineet and Mardani, Morteza and Vasanawala, Shreyas and Pauly, John},
  date = {2019},
  publisher = {[object Object]},
  doi = {10.48550/ARXIV.1901.11228},
  url = {https://arxiv.org/abs/1901.11228},
  urldate = {2024-03-12},
  abstract = {Reliable MRI is crucial for accurate interpretation in therapeutic and diagnostic tasks. However, undersampling during MRI acquisition as well as the overparameterized and non-transparent nature of deep learning (DL) leaves substantial uncertainty about the accuracy of DL reconstruction. With this in mind, this study aims to quantify the uncertainty in image recovery with DL models. To this end, we first leverage variational autoencoders (VAEs) to develop a probabilistic reconstruction scheme that maps out (low-quality) short scans with aliasing artifacts to the diagnostic-quality ones. The VAE encodes the acquisition uncertainty in a latent code and naturally offers a posterior of the image from which one can generate pixel variance maps using Monte-Carlo sampling. Accurately predicting risk requires knowledge of the bias as well, for which we leverage Stein's Unbiased Risk Estimator (SURE) as a proxy for mean-squared-error (MSE). Extensive empirical experiments are performed for Knee MRI reconstruction under different training losses (adversarial and pixel-wise) and unrolled recurrent network architectures. Our key observations indicate that: 1) adversarial losses introduce more uncertainty; and 2) recurrent unrolled nets reduce the prediction uncertainty and risk.},
  version = {3},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,Machine Learning (cs.LG)},
  file = {/Users/luca/Documents/literature/zotero/edupuganti2019.pdf}
}

@article{eldridge2016,
  title = {A New Method for Ecoacoustics? {{Toward}} the Extraction and Evaluation of Ecologically-Meaningful Soundscape Components Using Sparse Coding Methods},
  shorttitle = {A New Method for Ecoacoustics?},
  author = {Eldridge, Alice and Casey, Michael and Moscoso, Paola and Peck, Mika},
  date = {2016-06-30},
  journaltitle = {PeerJ},
  volume = {4},
  pages = {e2108},
  issn = {2167-8359},
  doi = {10.7717/peerj.2108},
  url = {https://peerj.com/articles/2108},
  urldate = {2023-06-21},
  abstract = {Passive acoustic monitoring is emerging as a promising non-invasive proxy for ecological complexity with potential as a tool for remote assessment and monitoring (Sueur \& Farina, 2015). Rather than attempting to recognise species-specific calls, either manually or automatically, there is a growing interest in evaluating the global acoustic environment. Positioned within the conceptual framework of ecoacoustics, a growing number of indices have been proposed which aim to capture community-level dynamics by (e.g., Pieretti, Farina \& Morri, 2011; Farina, 2014; Sueur et al., 2008b) by providing statistical summaries of the frequency or time domain signal. Although promising, the ecological relevance and efficacy as a monitoring tool of these indices is still unclear. In this paper we suggest that by virtue of operating in the time               or               frequency domain, existing indices are limited in their ability to access key structural information in the spectro-temporal domain. Alternative methods in which time-frequency dynamics are preserved are considered. Sparse-coding and source separation algorithms (specifically, shift-invariant probabilistic latent component analysis in 2D) are proposed as a means to access and summarise time-frequency dynamics which may be more ecologically-meaningful.},
  langid = {english},
  keywords = {new},
  file = {/Users/luca/Documents/literature/zotero/eldridge2016.pdf}
}

@dataset{eldridge2018,
  title = {Data {{For}} "{{Sounding Out Ecoacoustic Metrics}}: {{Avian Species Richness Is Predicted By Acoustic Indices In Temperate But Not Tropical Habitats}}"},
  shorttitle = {Data {{For}} "{{Sounding Out Ecoacoustic Metrics}}},
  author = {Eldridge, Alice and Moscoso, Paola and Guyot, Patrice and Peck, Mika},
  date = {2018-05-29},
  publisher = {Zenodo},
  doi = {10.5281/ZENODO.1255218},
  url = {https://zenodo.org/record/1255218},
  urldate = {2023-05-23},
  abstract = {This deposit contains the data for the paper {$<$}strong{$>$}A Multi-habitat, Comparative Evaluation of Ecoacoustic Indices for Biodiversity Monitoring: Acoustic Indices Predict Avian Species Richness in Temperate but not Tropical Habitats. (Ecological Indicators) {$<$}/strong{$>$}The dataset contains a series of 1 min wav files recorded across UK and Ecuadorian habitats. Each one has 26 acoustic indices calculated on it, and a full list of avian species and abundances and GPS data for each sample site. Abstract Affordable, autonomous recording devices facilitate large scale acoustic monitoring and Rapid Acoustic Survey is emerging as a cost-effective approach to ecological monitoring; the success of the approach rests on the development of computational methods by which biodiversity metrics can be automatically derived from remotely collected audio data. Dozens of indices have been proposed to date, but systematic validation against classical, in situ diversity measures. This study conducted the most comprehensive comparative evaluation to date of the relationship between avian species diversity and a suite of acoustic indices across a wide range of ecological conditions. Acoustic surveys were carried out across habitat gradients in temperate and tropical biomes. Baseline avian species richness and subjective multi-taxa biophonic density estimates were established through aural counting by expert ornithologists. 26 acoustic indices were calculated and compared to observed variations in species diversity. Five acoustic diversity indices (Bioacoustic Index, Acoustic Diversity Index, Acoustic Evenness Index, Acoustic Entropy, and the Normalised Difference Sound Index) were assessed as well as three simple acoustic descriptors (root-mean-square, spectral centroid and zero-crossing rate). Highly significant correlations, of up to 65\%, between acoustic indices and avian species richness were observed across temperate habitats, supporting the use of automated acoustic indices in biodiversity monitoring where a single vocal taxon dominates. Significant, weaker correlations were observed in neotropical habitats which host multiple non-avian vocalizing species. Multivariate classification analyses suggest that AIs also track observed differences in habitat-dependent community composition and that each habitat has a distinct soundscape. Multivariate analyses of the relative predictive power of AIs show that compound indices are more powerful predictors of avian species richness than any single index and simple descriptors contribute to predicting avian diversity in multi-taxa tropical environments. Our results support the use of community level acoustic indices as a proxy for species richness and point to the potential for tracking of habitat-dependent changes in community composition. Recommendations for the design of compound indices for multi-taxa community composition appraisal are put forward, with consideration for the requirements of next generation, low power remote monitoring networks.   {$<$}strong{$>$}Sampling Methods (extract from paper){$<$}/strong{$>$} Acoustic surveys were carried out along a gradient of habitat degradation (1 forested, 2 regenerating forest and 3 agricultural land) in South East (SE) England and North Western (NW) Ecuador. The six sites (UK1, UK2, UK3, EC1, EC2, EC3) were sampled consecutively from May 6th - Aug 25th 2015. All UK sites were in the county of Sussex, in SE England, an area of weald clays (Fig. 2, left) and included ancient woodland (UK1), regenerating farmland with patches of woodland (UK2) and a downland barley farm (UK3).1 min mono audio recordings made every 15 minutes at three different habitats in the UK Ten day acoustic surveys were carried out consecutively at each study site using 15 Wildlife Acoustics Song Meter audio field recorders. Sampling points were arranged in a grid at a minimum distance of 200 m to minimise pseudo replication (the sound of most species being attenuated over this distance in all biomes). Altitudinal range of sample points across sites was minimised in order to prevent introduction of extraneous, confounding gradients (UK varied between 10 m – 50 m and Ecuador 130 m – 390 m). Recording schedules captured 1 min every 15 min around the clock for 10 days at each site, resulting in 960 recordings at each of 15 sample points for 3 habitat types in 2 different climates (86,400 1 minute recordings in total). Data across the 15 sample points was pooled; inter-site variation was not explored in the current analyses. In the UK 3½ hours of each dawn chorus was sampled starting at 1 hour before sunrise. This range was determined to capture the onset, progression and peak of the dawn chorus, creating a temporal gradient. The equatorial dawn chorus is more compact and was sampled for 2¼ hours starting 15 mins before sunrise, capturing a comparable chorus onset and peak.},
  langid = {english},
  keywords = {Ecoacoustics,Rapid Acoustic Survey}
}

@incollection{feiner2023,
  title = {Propagation and {{Attribution}} of {{Uncertainty}} in {{Medical Imaging Pipelines}}},
  booktitle = {Uncertainty for {{Safe Utilization}} of {{Machine Learning}} in {{Medical Imaging}}},
  author = {Feiner, Leonhard F. and Menten, Martin J. and Hammernik, Kerstin and Hager, Paul and Huang, Wenqi and Rueckert, Daniel and Braren, Rickmer F. and Kaissis, Georgios},
  editor = {Sudre, Carole H. and Baumgartner, Christian F. and Dalca, Adrian and Mehta, Raghav and Qin, Chen and Wells, William M.},
  date = {2023},
  volume = {14291},
  pages = {1--11},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-44336-7_1},
  url = {https://link.springer.com/10.1007/978-3-031-44336-7_1},
  urldate = {2023-10-26},
  isbn = {978-3-031-44335-0 978-3-031-44336-7},
  langid = {english},
  keywords = {read},
  file = {/Users/luca/Documents/literature/zotero/feiner2023.pdf}
}

@article{figini2020,
  title = {Image {{Quality Transfer Enhances Contrast}} and {{Resolution}} of {{Low-Field Brain MRI}} in {{African Paediatric Epilepsy Patients}}},
  author = {Figini, Matteo and Lin, Hongxiang and Ogbole, Godwin and Arco, Felice D and Blumberg, Stefano B. and Carmichael, David W. and Tanno, Ryutaro and Kaden, Enrico and Brown, Biobele J. and Lagunju, Ikeoluwa and Cross, Helen J. and Fernandez-Reyes, Delmiro and Alexander, Daniel C.},
  date = {2020},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2003.07216},
  url = {https://arxiv.org/abs/2003.07216},
  urldate = {2023-10-23},
  abstract = {1.5T or 3T scanners are the current standard for clinical MRI, but low-field (\&lt;1T) scanners are still common in many lower- and middle-income countries for reasons of cost and robustness to power failures. Compared to modern high-field scanners, low-field scanners provide images with lower signal-to-noise ratio at equivalent resolution, leaving practitioners to compensate by using large slice thickness and incomplete spatial coverage. Furthermore, the contrast between different types of brain tissue may be substantially reduced even at equal signal-to-noise ratio, which limits diagnostic value. Recently the paradigm of Image Quality Transfer has been applied to enhance 0.36T structural images aiming to approximate the resolution, spatial coverage, and contrast of typical 1.5T or 3T images. A variant of the neural network U-Net was trained using low-field images simulated from the publicly available 3T Human Connectome Project dataset. Here we present qualitative results from real and simulated clinical low-field brain images showing the potential value of IQT to enhance the clinical utility of readily accessible low-field MRIs in the management of epilepsy.},
  version = {2},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Electrical engineering electronic engineering information engineering,FOS: Physical sciences,Image and Video Processing (eess.IV),Medical Physics (physics.med-ph),read},
  file = {/Users/luca/Documents/literature/zotero/figini2020.pdf}
}

@book{folland1984,
  title = {Real Analysis: Modern Techniques and Their Applications},
  shorttitle = {Real Analysis},
  author = {Folland, Gerald B.},
  date = {1984},
  series = {A {{Wiley-Interscience}} Publication},
  publisher = {Wiley},
  location = {New York},
  isbn = {978-0-471-80958-6},
  langid = {english},
  pagetotal = {350},
  file = {/Users/luca/Documents/literature/zotero/folland12.pdf}
}

@book{foster2023,
  title = {Generative Deep Learning: Teaching Machines to Paint, Write, Compose, and Play},
  shorttitle = {Generative Deep Learning},
  author = {Foster, David and Friston, K. J.},
  date = {2023},
  edition = {Second edition},
  publisher = {O'Reilly},
  location = {Beijing ; Boston},
  isbn = {978-1-09-813418-1},
  pagetotal = {426},
  keywords = {Artificial intelligence,Deep learning (Machine learning),Generative programming (Computer science),in progress,Machine learning,Neural networks (Computer science)},
  file = {/Users/luca/Documents/literature/zotero/foster2023.pdf}
}

@article{gawlikowski2023,
  title = {A Survey of Uncertainty in Deep Neural Networks},
  author = {Gawlikowski, Jakob and Tassi, Cedrique Rovile Njieutcheu and Ali, Mohsin and Lee, Jongseok and Humt, Matthias and Feng, Jianxiang and Kruspe, Anna and Triebel, Rudolph and Jung, Peter and Roscher, Ribana and Shahzad, Muhammad and Yang, Wen and Bamler, Richard and Zhu, Xiao Xiang},
  date = {2023-10},
  journaltitle = {Artificial Intelligence Review},
  shortjournal = {Artif Intell Rev},
  volume = {56},
  number = {S1},
  pages = {1513--1589},
  issn = {0269-2821, 1573-7462},
  doi = {10.1007/s10462-023-10562-9},
  url = {https://link.springer.com/10.1007/s10462-023-10562-9},
  urldate = {2023-11-01},
  abstract = {Abstract             Over the last decade, neural networks have reached almost every field of science and become a crucial part of various real world applications. Due to the increasing spread, confidence in neural network predictions has become more and more important. However, basic neural networks do not deliver certainty estimates or suffer from over- or under-confidence, i.e. are badly calibrated. To overcome this, many researchers have been working on understanding and quantifying uncertainty in a neural network’s prediction. As a result, different types and sources of uncertainty have been identified and various approaches to measure and quantify uncertainty in neural networks have been proposed. This work gives a comprehensive overview of uncertainty estimation in neural networks, reviews recent advances in the field, highlights current challenges, and identifies potential research opportunities. It is intended to give anyone interested in uncertainty estimation in neural networks a broad overview and introduction, without presupposing prior knowledge in this field. For that, a comprehensive introduction to the most crucial sources of uncertainty is given and their separation into reducible model uncertainty and irreducible data uncertainty is presented. The modeling of these uncertainties based on deterministic neural networks, Bayesian neural networks (BNNs), ensemble of neural networks, and test-time data augmentation approaches is introduced and different branches of these fields as well as the latest developments are discussed. For a practical application, we discuss different measures of uncertainty, approaches for calibrating neural networks, and give an overview of existing baselines and available implementations. Different examples from the wide spectrum of challenges in the fields of medical image analysis, robotics, and earth observation give an idea of the needs and challenges regarding uncertainties in the practical applications of neural networks. Additionally, the practical limitations of uncertainty quantification methods in neural networks for mission- and safety-critical real world applications are discussed and an outlook on the next steps towards a broader usage of such methods is given.},
  langid = {english},
  keywords = {in progress},
  file = {/Users/luca/Documents/literature/zotero/gawlikowski2023.pdf}
}

@article{gerkmann2015,
  title = {Phase {{Processing}} for {{Single-Channel Speech Enhancement}}: {{History}} and Recent Advances},
  shorttitle = {Phase {{Processing}} for {{Single-Channel Speech Enhancement}}},
  author = {Gerkmann, Timo and Krawczyk-Becker, Martin and Le Roux, Jonathan},
  date = {2015-03},
  journaltitle = {IEEE Signal Processing Magazine},
  shortjournal = {IEEE Signal Process. Mag.},
  volume = {32},
  number = {2},
  pages = {55--66},
  issn = {1053-5888},
  doi = {10.1109/MSP.2014.2369251},
  url = {https://ieeexplore.ieee.org/document/7038277},
  urldate = {2023-09-30},
  keywords = {read},
  file = {/Users/luca/Documents/literature/zotero/gerkmann2015.pdf}
}

@article{ghahramani2015,
  title = {Probabilistic Machine Learning and Artificial Intelligence},
  author = {Ghahramani, Zoubin},
  date = {2015-05-28},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {521},
  number = {7553},
  pages = {452--459},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature14541},
  url = {https://www.nature.com/articles/nature14541},
  urldate = {2024-04-01},
  langid = {english},
  file = {/Users/luca/Documents/literature/zotero/ghahramani2015.pdf}
}

@article{ghoshal2021,
  title = {Estimating Uncertainty in Deep Learning for Reporting Confidence to Clinicians in Medical Image Segmentation and Diseases Detection},
  author = {Ghoshal, Biraja and Tucker, Allan and Sanghera, Bal and Lup Wong, Wai},
  date = {2021-05},
  journaltitle = {Computational Intelligence},
  shortjournal = {Computational Intelligence},
  volume = {37},
  number = {2},
  pages = {701--734},
  issn = {0824-7935, 1467-8640},
  doi = {10.1111/coin.12411},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/coin.12411},
  urldate = {2024-03-12},
  abstract = {Abstract             Deep learning (DL), which involves powerful black box predictors, has achieved a remarkable performance in medical image analysis, such as segmentation and classification for diagnosis. However, in spite of these successes, these methods focus exclusively on improving the accuracy of point predictions without assessing the quality of their outputs. Knowing how much confidence there is in a prediction is essential for gaining clinicians' trust in the technology. In this article, we propose an uncertainty estimation framework, called MC‐DropWeights, to approximate Bayesian inference in DL by imposing a Bernoulli distribution on the incoming or outgoing weights of the model, including neurones. We demonstrate that by decomposing predictive probabilities into two main types of uncertainty, aleatoric and epistemic, using the Bayesian Residual U‐Net (BRUNet) in image segmentation. Approximation methods in Bayesian DL suffer from the “mode collapse” phenomenon in variational inference. To address this problem, we propose a model which Ensembles of Monte‐Carlo DropWeights by varying the DropWeights rate. In segmentation, we introduce a predictive uncertainty estimator, which takes the mean of the standard deviations of the class probabilities associated with every class. However, in classification, we need an alternative approach since the predictive probabilities from a forward pass through the model does not capture uncertainty. The entropy of the predictive distribution is a measure of uncertainty, but its exponential depends on sample size. The plug‐in estimate in mutual information is subject to sampling bias. We propose Jackknife resampling, to correct for sample bias, which improves estimating uncertainty quality in image classification. We demonstrate that our deep ensemble MC‐DropWeights method, using the bias‐corrected estimator produces an equally good or better result in both quantified uncertainty estimation and quality of uncertainty estimates than approximate Bayesian neural networks in practice.},
  langid = {english},
  file = {/Users/luca/Documents/literature/zotero/ghoshal2021.pdf;/Users/luca/Documents/literature/zotero/ghoshal22.pdf}
}

@book{goodfellow2016,
  title = {Deep Learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  date = {2016},
  series = {Adaptive Computation and Machine Learning},
  publisher = {The MIT press},
  location = {Cambridge, Mass},
  isbn = {978-0-262-03561-3},
  langid = {english}
}

@article{griffin1984,
  title = {Signal Estimation from Modified Short-Time {{Fourier}} Transform},
  author = {Griffin, D. and {Jae Lim}},
  date = {1984-04},
  journaltitle = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
  shortjournal = {IEEE Trans. Acoust., Speech, Signal Process.},
  volume = {32},
  number = {2},
  pages = {236--243},
  issn = {0096-3518},
  doi = {10.1109/TASSP.1984.1164317},
  url = {http://ieeexplore.ieee.org/document/1164317/},
  urldate = {2023-08-01},
  langid = {english},
  keywords = {read},
  file = {/Users/luca/Documents/literature/zotero/griffin1984.pdf}
}

@article{gu2023,
  title = {Mamba: {{Linear-Time Sequence Modeling}} with {{Selective State Spaces}}},
  shorttitle = {Mamba},
  author = {Gu, Albert and Dao, Tri},
  date = {2023},
  publisher = {[object Object]},
  doi = {10.48550/ARXIV.2312.00752},
  url = {https://arxiv.org/abs/2312.00752},
  urldate = {2024-03-06},
  abstract = {Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution and recurrent models, and structured state space models (SSMs) have been developed to address Transformers' computational inefficiency on long sequences, but they have not performed as well as attention on important modalities such as language. We identify that a key weakness of such models is their inability to perform content-based reasoning, and make several improvements. First, simply letting the SSM parameters be functions of the input addresses their weakness with discrete modalities, allowing the model to selectively propagate or forget information along the sequence length dimension depending on the current token. Second, even though this change prevents the use of efficient convolutions, we design a hardware-aware parallel algorithm in recurrent mode. We integrate these selective SSMs into a simplified end-to-end neural network architecture without attention or even MLP blocks (Mamba). Mamba enjoys fast inference (5\$\textbackslash times\$ higher throughput than Transformers) and linear scaling in sequence length, and its performance improves on real data up to million-length sequences. As a general sequence model backbone, Mamba achieves state-of-the-art performance across several modalities such as language, audio, and genomics. On language modeling, our Mamba-3B model outperforms Transformers of the same size and matches Transformers twice its size, both in pretraining and downstream evaluation.},
  version = {1},
  keywords = {Artificial Intelligence (cs.AI),FOS: Computer and information sciences,Machine Learning (cs.LG)},
  file = {/Users/luca/Documents/literature/zotero/gu2023.pdf}
}

@article{hammernik2022,
  title = {Physics-{{Driven Deep Learning}} for {{Computational Magnetic Resonance Imaging}}},
  author = {Hammernik, Kerstin and Küstner, Thomas and Yaman, Burhaneddin and Huang, Zhengnan and Rueckert, Daniel and Knoll, Florian and Akçakaya, Mehmet},
  date = {2022},
  publisher = {[object Object]},
  doi = {10.48550/ARXIV.2203.12215},
  url = {https://arxiv.org/abs/2203.12215},
  urldate = {2024-04-01},
  abstract = {Physics-driven deep learning methods have emerged as a powerful tool for computational magnetic resonance imaging (MRI) problems, pushing reconstruction performance to new limits. This article provides an overview of the recent developments in incorporating physics information into learning-based MRI reconstruction. We consider inverse problems with both linear and non-linear forward models for computational MRI, and review the classical approaches for solving these. We then focus on physics-driven deep learning approaches, covering physics-driven loss functions, plug-and-play methods, generative models, and unrolled networks. We highlight domain-specific challenges such as real- and complex-valued building blocks of neural networks, and translational applications in MRI with linear and non-linear forward models. Finally, we discuss common issues and open challenges, and draw connections to the importance of physics-driven learning when combined with other downstream tasks in the medical imaging pipeline.},
  version = {3},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Electrical engineering electronic engineering information engineering,FOS: Physical sciences,Image and Video Processing (eess.IV),Machine Learning (cs.LG),Medical Physics (physics.med-ph),Signal Processing (eess.SP)},
  file = {/Users/luca/Documents/literature/zotero/hammernik2022.pdf}
}

@inproceedings{hasanDeepNeuralNetwork2021,
  title = {A {{Deep Neural Network}} for {{Multi-class Dry Beans Classification}}},
  booktitle = {2021 24th {{International Conference}} on {{Computer}} and {{Information Technology}} ({{ICCIT}})},
  author = {Hasan, Md. Mahadi and Islam, Muhammad Usama and Sadeq, Muhammad Jafar},
  date = {2021-12-18},
  pages = {1--5},
  publisher = {IEEE},
  location = {Dhaka, Bangladesh},
  doi = {10.1109/ICCIT54785.2021.9689905},
  url = {https://ieeexplore.ieee.org/document/9689905/},
  urldate = {2023-05-12},
  eventtitle = {2021 24th {{International Conference}} on {{Computer}} and {{Information Technology}} ({{ICCIT}})},
  isbn = {978-1-66549-435-9}
}

@book{hastie2015,
  title = {Statistical Learning with Sparsity: The Lasso and Generalizations},
  shorttitle = {Statistical Learning with Sparsity},
  author = {Hastie, Trevor and Tibshirani, Robert and Wainwright, Martin},
  date = {2015},
  series = {Monographs on Statistics and Applied Probability},
  number = {143},
  publisher = {CRC Press, Taylor \& Francis Group},
  location = {Boca Raton},
  isbn = {978-1-4987-1216-3},
  pagetotal = {351},
  keywords = {Least squares,Linear models (Statistics),Mathematical statistics,new,Proof theory},
  file = {/Users/luca/Documents/literature/zotero/hastie2015.pdf}
}

@article{he2015,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  date = {2015},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1512.03385},
  url = {https://arxiv.org/abs/1512.03385},
  urldate = {2023-11-11},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \&amp; COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  version = {1},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences}
}

@article{hendrycks2016,
  title = {Gaussian {{Error Linear Units}} ({{GELUs}})},
  author = {Hendrycks, Dan and Gimpel, Kevin},
  date = {2016},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1606.08415},
  url = {https://arxiv.org/abs/1606.08415},
  urldate = {2023-11-24},
  abstract = {We propose the Gaussian Error Linear Unit (GELU), a high-performing neural network activation function. The GELU activation function is \$xΦ(x)\$, where \$Φ(x)\$ the standard Gaussian cumulative distribution function. The GELU nonlinearity weights inputs by their value, rather than gates inputs by their sign as in ReLUs (\$x\textbackslash mathbf\{1\}\_\{x\&gt;0\}\$). We perform an empirical evaluation of the GELU nonlinearity against the ReLU and ELU activations and find performance improvements across all considered computer vision, natural language processing, and speech tasks.},
  version = {5},
  keywords = {FOS: Computer and information sciences,Machine Learning (cs.LG)},
  file = {/Users/luca/Documents/literature/zotero/hendrycks2016.pdf}
}

@article{hori2021,
  title = {Low-{{Field Magnetic Resonance Imaging}}: {{Its History}} and {{Renaissance}}},
  shorttitle = {Low-{{Field Magnetic Resonance Imaging}}},
  author = {Hori, Masaaki and Hagiwara, Akifumi and Goto, Masami and Wada, Akihiko and Aoki, Shigeki},
  date = {2021-11},
  journaltitle = {Investigative Radiology},
  shortjournal = {Invest Radiol},
  volume = {56},
  number = {11},
  pages = {669--679},
  issn = {1536-0210, 0020-9996},
  doi = {10.1097/RLI.0000000000000810},
  url = {https://journals.lww.com/10.1097/RLI.0000000000000810},
  urldate = {2023-10-22},
  abstract = {Abstract             Low-field magnetic resonance imaging (MRI) systems have seen a renaissance recently due to improvements in technology (both hardware and software). Originally, the performance of low-field MRI systems was rated lower than their actual clinical usefulness, and they were viewed as low-cost but poorly performing systems. However, various applications similar to high-field MRI systems (1.5 T and 3 T) have gradually become possible, culminating with high-performance low-field MRI systems and their adaptations now being proposed that have unique advantages over high-field MRI systems in various aspects. This review article describes the physical characteristics of low-field MRI systems and presents both their advantages and disadvantages for clinical use (past to present), along with their cutting-edge clinical applications.},
  langid = {english},
  keywords = {read},
  file = {/Users/luca/Documents/literature/zotero/hori2021.pdf}
}

@article{huang2016,
  title = {Densely {{Connected Convolutional Networks}}},
  author = {Huang, Gao and Liu, Zhuang and family=Maaten, given=Laurens, prefix=van der, useprefix=true and Weinberger, Kilian Q.},
  date = {2016},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1608.06993},
  url = {https://arxiv.org/abs/1608.06993},
  urldate = {2023-11-30},
  abstract = {Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet .},
  version = {5},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,Machine Learning (cs.LG)},
  file = {/Users/luca/Documents/literature/zotero/huang2016.pdf}
}

@article{huang2024,
  title = {{{MambaMIR}}: {{An Arbitrary-Masked Mamba}} for {{Joint Medical Image Reconstruction}} and {{Uncertainty Estimation}}},
  shorttitle = {{{MambaMIR}}},
  author = {Huang, Jiahao and Yang, Liutao and Wang, Fanwen and Wu, Yinzhe and Nan, Yang and Aviles-Rivero, Angelica I. and Schönlieb, Carola-Bibiane and Zhang, Daoqiang and Yang, Guang},
  date = {2024},
  publisher = {[object Object]},
  doi = {10.48550/ARXIV.2402.18451},
  url = {https://arxiv.org/abs/2402.18451},
  urldate = {2024-03-06},
  abstract = {The recent Mamba model has shown remarkable adaptability for visual representation learning, including in medical imaging tasks. This study introduces MambaMIR, a Mamba-based model for medical image reconstruction, as well as its Generative Adversarial Network-based variant, MambaMIR-GAN. Our proposed MambaMIR inherits several advantages, such as linear complexity, global receptive fields, and dynamic weights, from the original Mamba model. The innovated arbitrary-mask mechanism effectively adapt Mamba to our image reconstruction task, providing randomness for subsequent Monte Carlo-based uncertainty estimation. Experiments conducted on various medical image reconstruction tasks, including fast MRI and SVCT, which cover anatomical regions such as the knee, chest, and abdomen, have demonstrated that MambaMIR and MambaMIR-GAN achieve comparable or superior reconstruction results relative to state-of-the-art methods. Additionally, the estimated uncertainty maps offer further insights into the reliability of the reconstruction quality. The code is publicly available at https://github.com/ayanglab/MambaMIR.},
  version = {1},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Electrical engineering electronic engineering information engineering,Image and Video Processing (eess.IV)},
  file = {/Users/luca/Documents/literature/zotero/huang22.pdf}
}

@article{hullermeier2021,
  title = {Aleatoric and Epistemic Uncertainty in Machine Learning: An Introduction to Concepts and Methods},
  shorttitle = {Aleatoric and Epistemic Uncertainty in Machine Learning},
  author = {Hüllermeier, Eyke and Waegeman, Willem},
  date = {2021-03},
  journaltitle = {Machine Learning},
  shortjournal = {Mach Learn},
  volume = {110},
  number = {3},
  pages = {457--506},
  issn = {0885-6125, 1573-0565},
  doi = {10.1007/s10994-021-05946-3},
  url = {https://link.springer.com/10.1007/s10994-021-05946-3},
  urldate = {2023-10-23},
  abstract = {Abstract                            The notion of uncertainty is of major importance in machine learning and constitutes a key element of machine learning methodology. In line with the statistical tradition, uncertainty has long been perceived as almost synonymous with standard probability and probabilistic predictions. Yet, due to the steadily increasing relevance of machine learning for practical applications and related issues such as safety requirements, new problems and challenges have recently been identified by machine learning scholars, and these problems may call for new methodological developments. In particular, this includes the importance of distinguishing between (at least) two different types of uncertainty, often referred to as               aleatoric               and               epistemic               . In this paper, we provide an introduction to the topic of uncertainty in machine learning as well as an overview of attempts so far at handling uncertainty in general and formalizing this distinction in particular.},
  langid = {english},
  keywords = {in progress},
  file = {/Users/luca/Documents/literature/zotero/hullermeier2021.pdf}
}

@inproceedings{iagaru2023,
  title = {Uncertainty {{Quantification}} with {{Deep Ensemble Methods}} for {{Super-Resolution}} of {{Sentinel}} 2 {{Satellite Images}}},
  booktitle = {The 42nd {{International Workshop}} on {{Bayesian Inference}} and {{Maximum Entropy Methods}} in {{Science}} and {{Engineering}}},
  author = {Iagaru, David and Gottschling, Nina Maria},
  date = {2023-11-27},
  pages = {4},
  publisher = {MDPI},
  doi = {10.3390/psf2023009004},
  url = {https://www.mdpi.com/2673-9984/9/1/4},
  urldate = {2024-03-12},
  eventtitle = {International {{Workshop}} on {{Bayesian Inference}} and {{Maximum Entropy Methods}} in {{Science}} and {{Engineering}}},
  langid = {english},
  file = {/Users/luca/Documents/literature/zotero/iagaru2023.pdf}
}

@article{iglesias2022,
  title = {Accurate Super-Resolution Low-Field Brain {{MRI}}},
  author = {Iglesias, Juan Eugenio and Schleicher, Riana and Laguna, Sonia and Billot, Benjamin and Schaefer, Pamela and McKaig, Brenna and Goldstein, Joshua N. and Sheth, Kevin N. and Rosen, Matthew S. and Kimberly, W. Taylor},
  date = {2022},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2202.03564},
  url = {https://arxiv.org/abs/2202.03564},
  urldate = {2023-11-30},
  abstract = {The recent introduction of portable, low-field MRI (LF-MRI) into the clinical setting has the potential to transform neuroimaging. However, LF-MRI is limited by lower resolution and signal-to-noise ratio, leading to incomplete characterization of brain regions. To address this challenge, recent advances in machine learning facilitate the synthesis of higher resolution images derived from one or multiple lower resolution scans. Here, we report the extension of a machine learning super-resolution (SR) algorithm to synthesize 1 mm isotropic MPRAGE-like scans from LF-MRI T1-weighted and T2-weighted sequences. Our initial results on a paired dataset of LF and high-field (HF, 1.5T-3T) clinical scans show that: (i) application of available automated segmentation tools directly to LF-MRI images falters; but (ii) segmentation tools succeed when applied to SR images with high correlation to gold standard measurements from HF-MRI (e.g., r = 0.85 for hippocampal volume, r = 0.84 for the thalamus, r = 0.92 for the whole cerebrum). This work demonstrates proof-of-principle post-processing image enhancement from lower resolution LF-MRI sequences. These results lay the foundation for future work to enhance the detection of normal and abnormal image findings at LF and ultimately improve the diagnostic performance of LF-MRI. Our tools are publicly available on FreeSurfer (surfer.nmr.mgh.harvard.edu/).},
  version = {1},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Electrical engineering electronic engineering information engineering,Image and Video Processing (eess.IV),new}
}

@article{inglese2022,
  title = {A Predictive Model Using the Mesoscopic Architecture of the Living Brain to Detect {{Alzheimer}}’s Disease},
  author = {Inglese, Marianna and Patel, Neva and Linton-Reid, Kristofer and Loreto, Flavia and Win, Zarni and Perry, Richard J. and Carswell, Christopher and Grech-Sollars, Matthew and Crum, William R. and Lu, Haonan and Malhotra, Paresh A. and {the Alzheimer’s Disease Neuroimaging Initiative} and Silbert, Lisa C. and Lind, Betty and Crissey, Rachel and Kaye, Jeffrey A. and Carter, Raina and Dolen, Sara and Quinn, Joseph and Schneider, Lon S. and Pawluczyk, Sonia and Becerra, Mauricio and Teodoro, Liberty and Dagerman, Karen and Spann, Bryan M. and Brewer, James and Vanderswag, Helen and Fleisher, Adam and Ziolkowski, Jaimie and Heidebrink, Judith L. and {Zbizek-Nulph} and Lord, Joanne L. and Zbizek-Nulph, Lisa and Petersen, Ronald and Mason, Sara S. and Albers, Colleen S. and Knopman, David and Johnson, Kris and Villanueva-Meyer, Javier and Pavlik, Valory and Pacini, Nathaniel and Lamb, Ashley and Kass, Joseph S. and Doody, Rachelle S. and Shibley, Victoria and Chowdhury, Munir and Rountree, Susan and Dang, Mimi and Stern, Yaakov and Honig, Lawrence S. and Mintz, Akiva and Ances, Beau and Morris, John C. and Winkfield, David and Carroll, Maria and Stobbs-Cucchi, Georgia and Oliver, Angela and Creech, Mary L. and Mintun, Mark A. and Schneider, Stacy and Geldmacher, David and Love, Marissa Natelson and Griffith, Randall and Clark, David and Brockington, John and Marson, Daniel and Grossman, Hillel and Goldstein, Martin A. and Greenberg, Jonathan and Mitsis, Effie and Shah, Raj C. and Lamar, Melissa and Sood, Ajay and Blanchard, Kimberly S. and Fleischman, Debra and Arfanakis, Konstantinos and Samuels, Patricia and Duara, Ranjan and Greig-Custo, Maria T. and Rodriguez, Rosemarie and Albert, Marilyn and Varon, Daniel and Onyike, Chiadi and Farrington, Leonie and Rudow, Scott and Brichko, Rottislav and Greig, Maria T. and Kielb, Stephanie and Smith, Amanda and Raj, Balebail Ashok and Fargher, Kristin and Sadowski, Martin and Wisniewski, Thomas and Shulman, Melanie and Faustin, Arline and Rao, Julia and Castro, Karen M. and Ulysse, Anaztasia and Chen, Shannon and Sheikh, Mohammed O. and Singleton-Garvin, Jamika and Doraiswamy, P. Murali and Petrella, Jeffrey R. and James, Olga and Wong, Terence Z. and Borges-Neto, Salvador and Karlawish, Jason H. and Wolk, David A. and Vaishnavi, Sanjeev and Clark, Christopher M. and Arnold, Steven E. and Smith, Charles D. and Jicha, Gregory A. and El Khouli, Riham and Raslau, Flavius D. and Lopez, Oscar L. and Zmuda, Michelle and Butters, Meryl and Oakley, MaryAnn and Simpson, Donna M. and Porsteinsson, Anton P. and Martin, Kim and Kowalski, Nancy and Martin, Kimberly S. and Keltz, Melanie and Goldstein, Bonnie S. and Makino, Kelly M. and Ismail, M. Saleem and Brand, Connie and Reist, Christopher and Thai, Gaby and Pierce, Aimee and Yanez, Beatriz and Sosa, Elizabeth and Witbracht, Megan and Kelley, Brendan and Nguyen, Trung and Womack, Kyle and Mathews, Dana and Quiceno, Mary and Levey, Allan I. and Lah, James J. and Hajjar, Ihab and Cellar, Janet S. and Burns, Jeffrey M. and Swerdlow, Russell H. and Brooks, William M. and Silverman, Daniel H. S. and Kremen, Sarah and Apostolova, Liana and Tingus, Kathleen and Lu, Po H. and Bartzokis, George and Woo, Ellen and Teng, Edmond and Graff-Radford, Neill R. and Parfitt, Francine and Poki-Walker, Kim and Farlow, Martin R. and Hake, Ann Marie and Matthews, Brandy R. and Brosch, Jared R. and Herring, Scott and Van Dyck, Christopher H. and Mecca, Adam P. and Good, Susan P. and MacAvoy, Martha G. and Carson, Richard E. and Varma, Pradeep and Chertkow, Howard and Vaitekunis, Susan and Hosein, Chris and Black, Sandra and Stefanovic, Bojana and Heyn, Chris Chinthaka and Hsiung, Ging-Yuek Robin and Kim, Ellen and Mudge, Benita and Sossi, Vesna and Feldman, Howard and Assaly, Michele and Finger, Elizabeth and Pasternak, Stephen and Rachinsky, Irina and Kertesz, Andrew and Drost, Dick and Rogers, John and Grant, Ian and Muse, Brittanie and Rogalski, Emily and Mesulam, Jordan Robson M. -Marsel and Kerwin, Diana and Wu, Chuang-Kuo and Johnson, Nancy and Lipowski, Kristine and Weintraub, Sandra and Bonakdarpour, Borna and Pomara, Nunzio and Hernando, Raymundo and Sarrael, Antero and Rosen, Howard J. and Mackin, Scott and Nelson, Craig and Bickford, David and Au, Yiu Ho and Scherer, Kelly and Catalinotto, Daniel and Stark, Samuel and Ong, Elise and Fernandez, Dariella and Miller, Bruce L. and Rosen, Howard and Perry, David and Turner, Raymond Scott and Johnson, Kathleen and Reynolds, Brigid and MCCann, Kelly and Poe, Jessica and Sperling, Reisa A. and Johnson, Keith A. and Marshall, Gad A. and Yesavage, Jerome and Taylor, Joy L. and Chao, Steven and Coleman, Jaila and White, Jessica D. and Lane, Barton and Rosen, Allyson and Tinklenberg, Jared and Belden, Christine M. and Atri, Alireza and Spann, Bryan M. and Zamrini, Kelly A. Clark Edward and Sabbagh, Marwan and Killiany, Ronald and Stern, Robert and Mez, Jesse and Kowall, Neil and Budson, Andrew E. and Obisesan, Thomas O. and Ntekim, Oyonumo E. and Wolday, Saba and Khan, Javed I. and Nwulia, Evaristus and Nadarajah, Sheeba and Lerner, Alan and Ogrocki, Paula and Tatsuoka, Curtis and Fatica, Parianne and Fletcher, Evan and Maillard, Pauline and Olichney, John and DeCarli, Charles and Carmichael, Owen and Bates, Vernice and Capote, Horacio and Rainka, Michelle and Borrie, Michael and Lee, T. -Y and Bartha, Rob and Johnson, Sterling and Asthana, Sanjay and Carlsson, Cynthia M. and Perrin, Allison and Burke, Anna and Scharre, Douglas W. and Kataki, Maria and Tarawneh, Rawan and Kelley, Brendan and Hart, David and Zimmerman, Earl A. and Celmins, Dzintra and Miller, Delwyn D. and Ponto, Laura L. Boles and Smith, Karen Ekstam and Koleva, Hristina and Shim, Hyungsub and Nam, Ki Won and Schultz, Susan K. and Williamson, Jeff D. and Craft, Suzanne and Cleveland, Jo and Yang, Mia and Sink, Kaycee M. and Ott, Brian R. and Drake, Jonathan and Tremont, Geoffrey and Daiello, Lori A. and Drake, Jonathan D. and Sabbagh, Marwan and Ritter, Aaron and Bernick, Charles and Munic, Donna and Mintz, Akiva and O’Connelll, Abigail and Mintzer, Jacobo and Wiliams, Arthur and Masdeu, Joseph and Shi, Jiong and Garcia, Angelica and Sabbagh, Marwan and Newhouse, Paul and Potkin, Steven and Salloway, Stephen and Malloy, Paul and Correia, Stephen and Kittur, Smita and Pearlson, Godfrey D. and Blank, Karen and Anderson, Karen and Flashman, Laura A. and Seltzer, Marc and Hynes, Mary L. and Santulli, Robert B. and Relkin, Norman and Chiang, Gloria and Lin, Michael and Ravdin, Lisa and Lee, Athena and Sadowsky, Carl and Martinez, Walter and Villena, Teresa and Peskind, Elaine R. and Petrie, Eric C. and Li, Gail and Aboagye, Eric O.},
  date = {2022-06-20},
  journaltitle = {Communications Medicine},
  shortjournal = {Commun Med},
  volume = {2},
  number = {1},
  pages = {70},
  issn = {2730-664X},
  doi = {10.1038/s43856-022-00133-4},
  url = {https://www.nature.com/articles/s43856-022-00133-4},
  urldate = {2023-11-13},
  abstract = {Abstract                            Background               Alzheimer’s disease, the most common cause of dementia, causes a progressive and irreversible deterioration of cognition that can sometimes be difficult to diagnose, leading to suboptimal patient care.                                         Methods               We developed a predictive model that computes multi-regional statistical morpho-functional mesoscopic traits from T1-weighted MRI scans, with or without cognitive scores. For each patient, a biomarker called “Alzheimer’s Predictive Vector” (ApV) was derived using a two-stage least absolute shrinkage and selection operator (LASSO).                                         Results                                The ApV reliably discriminates between people with (ADrp) and without (nADrp) Alzheimer’s related pathologies (98\% and 81\% accuracy between ADrp - including the early form, mild cognitive impairment - and nADrp in internal and external hold-out test sets, respectively), without any a priori assumptions or need for neuroradiology reads. The new test is superior to standard hippocampal atrophy (26\% accuracy) and cerebrospinal fluid beta amyloid measure (62\% accuracy). A multiparametric analysis compared DTI-MRI derived fractional anisotropy, whose readout of neuronal loss agrees with ADrp phenotype, and                 SNPrs2075650                 is significantly altered in patients with ADrp-like phenotype.                                                        Conclusions               This new data analytic method demonstrates potential for increasing accuracy of Alzheimer diagnosis.},
  langid = {english},
  keywords = {new},
  file = {/Users/luca/Documents/literature/zotero/inglese2022.pdf}
}

@inproceedings{itakura1987,
  title = {Distance Measure for Speech Recognition Based on the Smoothed Group Delay Spectrum},
  booktitle = {{{ICASSP}} '87. {{IEEE International Conference}} on {{Acoustics}}, {{Speech}}, and {{Signal Processing}}},
  author = {Itakura, F. and Umezaki, T.},
  date = {1987},
  volume = {12},
  pages = {1257--1260},
  publisher = {{Institute of Electrical and Electronics Engineers}},
  location = {Dallas, TX, USA},
  doi = {10.1109/ICASSP.1987.1169476},
  url = {http://ieeexplore.ieee.org/document/1169476/},
  urldate = {2023-09-27},
  eventtitle = {{{IEEE International Conference}} on {{Acoustics}}, {{Speech}}, and {{Signal Processing}}},
  keywords = {read},
  file = {/Users/luca/Documents/literature/zotero/itakura1987.pdf}
}

@inproceedings{javadi2023,
  title = {From {{Perception}} to {{Precision}}: {{Navigating Perceptual Loss}} in {{MRI Super-Resolution}}},
  shorttitle = {From {{Perception}} to {{Precision}}},
  booktitle = {2023 {{IEEE}} 23rd {{International Conference}} on {{Bioinformatics}} and {{Bioengineering}} ({{BIBE}})},
  author = {Javadi, Mohammad and Sharma, Rishabh and Tsiamyrtzis, Panagiotis and Shah, Shishir and Leiss, Ernst L. and Tsekos, Nikolaos V.},
  date = {2023-12-04},
  pages = {57--61},
  publisher = {IEEE},
  location = {Dayton, OH, USA},
  doi = {10.1109/BIBE60311.2023.00017},
  url = {https://ieeexplore.ieee.org/document/10431840/},
  urldate = {2024-04-16},
  eventtitle = {2023 {{IEEE}} 23rd {{International Conference}} on {{Bioinformatics}} and {{Bioengineering}} ({{BIBE}})},
  isbn = {9798350393118}
}

@book{jaynes2003,
  title = {Probability Theory: The Logic of Science},
  shorttitle = {Probability Theory},
  author = {Jaynes, E. T. and Bretthorst, G. Larry},
  date = {2003},
  publisher = {Cambridge University Press},
  location = {Cambridge, UK ; New York, NY},
  isbn = {978-0-521-59271-0},
  pagetotal = {727},
  keywords = {new,Probabilities},
  file = {/Users/luca/Documents/literature/zotero/jaynes22.pdf}
}

@article{kaneko2022,
  title = {{{iSTFTNet}}: {{Fast}} and {{Lightweight Mel-Spectrogram Vocoder Incorporating Inverse Short-Time Fourier Transform}}},
  shorttitle = {{{iSTFTNet}}},
  author = {Kaneko, Takuhiro and Tanaka, Kou and Kameoka, Hirokazu and Seki, Shogo},
  date = {2022},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2203.02395},
  url = {https://arxiv.org/abs/2203.02395},
  urldate = {2023-07-19},
  abstract = {In recent text-to-speech synthesis and voice conversion systems, a mel-spectrogram is commonly applied as an intermediate representation, and the necessity for a mel-spectrogram vocoder is increasing. A mel-spectrogram vocoder must solve three inverse problems: recovery of the original-scale magnitude spectrogram, phase reconstruction, and frequency-to-time conversion. A typical convolutional mel-spectrogram vocoder solves these problems jointly and implicitly using a convolutional neural network, including temporal upsampling layers, when directly calculating a raw waveform. Such an approach allows skipping redundant processes during waveform synthesis (e.g., the direct reconstruction of high-dimensional original-scale spectrograms). By contrast, the approach solves all problems in a black box and cannot effectively employ the time-frequency structures existing in a mel-spectrogram. We thus propose iSTFTNet, which replaces some output-side layers of the mel-spectrogram vocoder with the inverse short-time Fourier transform (iSTFT) after sufficiently reducing the frequency dimension using upsampling layers, reducing the computational cost from black-box modeling and avoiding redundant estimations of high-dimensional spectrograms. During our experiments, we applied our ideas to three HiFi-GAN variants and made the models faster and more lightweight with a reasonable speech quality. Audio samples are available at https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/istftnet/.},
  version = {1},
  keywords = {Audio and Speech Processing (eess.AS),FOS: Electrical engineering electronic engineering information engineering,Machine Learning (cs.LG),Machine Learning (stat.ML),read,Sound (cs.SD)},
  file = {/Users/luca/Documents/literature/zotero/kaneko2022.pdf}
}

@article{karras2017,
  title = {Progressive {{Growing}} of {{GANs}} for {{Improved Quality}}, {{Stability}}, and {{Variation}}},
  author = {Karras, Tero and Aila, Timo and Laine, Samuli and Lehtinen, Jaakko},
  date = {2017},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1710.10196},
  url = {https://arxiv.org/abs/1710.10196},
  urldate = {2023-07-09},
  abstract = {We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024\textasciicircum 2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.},
  version = {3},
  keywords = {Machine Learning (cs.LG),Machine Learning (stat.ML),Neural and Evolutionary Computing (cs.NE),new},
  file = {/Users/luca/Documents/literature/zotero/karras22.pdf}
}

@article{kim2015,
  title = {Accurate {{Image Super-Resolution Using Very Deep Convolutional Networks}}},
  author = {Kim, Jiwon and Lee, Jung Kwon and Lee, Kyoung Mu},
  date = {2015},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1511.04587},
  url = {https://arxiv.org/abs/1511.04587},
  urldate = {2023-11-29},
  abstract = {We present a highly accurate single-image super-resolution (SR) method. Our method uses a very deep convolutional network inspired by VGG-net used for ImageNet classification \textbackslash cite\{simonyan2015very\}. We find increasing our network depth shows a significant improvement in accuracy. Our final model uses 20 weight layers. By cascading small filters many times in a deep network structure, contextual information over large image regions is exploited in an efficient way. With very deep networks, however, convergence speed becomes a critical issue during training. We propose a simple yet effective training procedure. We learn residuals only and use extremely high learning rates (\$10\textasciicircum 4\$ times higher than SRCNN \textbackslash cite\{dong2015image\}) enabled by adjustable gradient clipping. Our proposed method performs better than existing methods in accuracy and visual improvements in our results are easily noticeable.},
  version = {2},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,Machine Learning (cs.LG),new},
  file = {/Users/luca/Documents/literature/zotero/kim2015.pdf}
}

@article{kingma2013,
  title = {Auto-{{Encoding Variational Bayes}}},
  author = {Kingma, Diederik P and Welling, Max},
  date = {2013},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1312.6114},
  url = {https://arxiv.org/abs/1312.6114},
  urldate = {2023-05-15},
  abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
  version = {11},
  keywords = {Machine Learning (cs.LG),Machine Learning (stat.ML),read},
  file = {/Users/luca/Documents/literature/zotero/kingma2013.pdf}
}

@article{kingma2019,
  title = {An {{Introduction}} to {{Variational Autoencoders}}},
  author = {Kingma, Diederik P. and Welling, Max},
  date = {2019},
  journaltitle = {Foundations and Trends® in Machine Learning},
  shortjournal = {FNT in Machine Learning},
  volume = {12},
  number = {4},
  pages = {307--392},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000056},
  url = {http://www.nowpublishers.com/article/Details/MAL-056},
  urldate = {2023-05-06},
  langid = {english},
  keywords = {in progress},
  file = {/Users/luca/Documents/literature/zotero/kingma2019.pdf}
}

@article{koklu2020,
  title = {Multiclass Classification of Dry Beans Using Computer Vision and Machine Learning Techniques},
  author = {Koklu, Murat and Ozkan, Ilker Ali},
  date = {2020-07},
  journaltitle = {Computers and Electronics in Agriculture},
  shortjournal = {Computers and Electronics in Agriculture},
  volume = {174},
  pages = {105507},
  issn = {01681699},
  doi = {10.1016/j.compag.2020.105507},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0168169919311573},
  urldate = {2023-05-06},
  abstract = {There is a wide range of genetic diversity of dry bean which is the most produced one among the edible legume crops in the world. Seed quality is definitely influential in crop production. Therefore, seed classification is essential for both marketing and production to provide the principles of sustainable agricultural systems. The primary objective of this study is to provide a method for obtaining uniform seed varieties from crop production, which is in the form of population, so the seeds are not certified as a sole variety. Thus, a computer vision system was developed to distinguish seven different registered varieties of dry beans with similar features in order to obtain uniform seed classification. For the classification model, images of 13,611 grains of 7 different registered dry beans were taken with a high-resolution camera. A user-friendly interface was designed using the MATLAB graphical user interface (GUI). Bean images obtained by computer vision system (CVS) were subjected to segmentation and feature extraction stages, and a total of 16 features; 12 dimension and 4 shape forms, were obtained from the grains. Multilayer perceptron (MLP), Support Vector Machine (SVM), k-Nearest Neighbors (kNN), Decision Tree (DT) classification models were created with 10-fold cross validation and performance metrics were compared. Overall correct classification rates have been determined as 91.73\%, 93.13\%, 87.92\% and 92.52\% for MLP, SVM, kNN and DT, respectively. The SVM classification model, which has the highest accuracy results, has classified the Barbunya, Bombay, Cali, Dermason, Horoz, Seker and Sira bean varieties with 92.36\%, 100.00\%, 95.03\%, 94.36\%, 94.92\%, 94.67\% and 86.84\%, respectively. With these results, the demands of the producers and the customers are largely met about obtaining uniform bean varieties.},
  langid = {english},
  keywords = {new},
  file = {/Users/luca/Documents/literature/zotero/koklu2020.pdf}
}

@article{krawczyk2014,
  title = {{{STFT Phase Reconstruction}} in {{Voiced Speech}} for an {{Improved Single-Channel Speech Enhancement}}},
  author = {Krawczyk, Martin and Gerkmann, Timo},
  date = {2014-12},
  journaltitle = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  shortjournal = {IEEE/ACM Trans. Audio Speech Lang. Process.},
  volume = {22},
  number = {12},
  pages = {1931--1940},
  issn = {2329-9290, 2329-9304},
  doi = {10.1109/TASLP.2014.2354236},
  url = {http://ieeexplore.ieee.org/document/6891278/},
  urldate = {2023-07-03},
  keywords = {read},
  file = {/Users/luca/Documents/literature/zotero/krawczyk2014.pdf}
}

@article{lakshminarayanan2016,
  title = {Simple and {{Scalable Predictive Uncertainty Estimation}} Using {{Deep Ensembles}}},
  author = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  date = {2016},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1612.01474},
  url = {https://arxiv.org/abs/1612.01474},
  urldate = {2023-08-14},
  abstract = {Deep neural networks (NNs) are powerful black box predictors that have recently achieved impressive performance on a wide spectrum of tasks. Quantifying predictive uncertainty in NNs is a challenging and yet unsolved problem. Bayesian NNs, which learn a distribution over weights, are currently the state-of-the-art for estimating predictive uncertainty; however these require significant modifications to the training procedure and are computationally expensive compared to standard (non-Bayesian) NNs. We propose an alternative to Bayesian NNs that is simple to implement, readily parallelizable, requires very little hyperparameter tuning, and yields high quality predictive uncertainty estimates. Through a series of experiments on classification and regression benchmarks, we demonstrate that our method produces well-calibrated uncertainty estimates which are as good or better than approximate Bayesian NNs. To assess robustness to dataset shift, we evaluate the predictive uncertainty on test examples from known and unknown distributions, and show that our method is able to express higher uncertainty on out-of-distribution examples. We demonstrate the scalability of our method by evaluating predictive uncertainty estimates on ImageNet.},
  version = {3},
  keywords = {in progress,Machine Learning (cs.LG),Machine Learning (stat.ML)},
  file = {/Users/luca/Documents/literature/zotero/lakshminarayanan2016.pdf}
}

@article{lang2020,
  title = {Circular {{Regression Trees}} and {{Forests}} with an {{Application}} to {{Probabilistic Wind Direction Forecasting}}},
  author = {Lang, Moritz N. and Schlosser, Lisa and Hothorn, Torsten and Mayr, Georg J. and Stauffer, Reto and Zeileis, Achim},
  date = {2020},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2001.00412},
  url = {https://arxiv.org/abs/2001.00412},
  urldate = {2023-10-30},
  abstract = {While circular data occur in a wide range of scientific fields, the methodology for distributional modeling and probabilistic forecasting of circular response variables is rather limited. Most of the existing methods are built on the framework of generalized linear and additive models, which are often challenging to optimize and to interpret. Therefore, we suggest circular regression trees and random forests as an intuitive alternative approach that is relatively easy to fit. Building on previous ideas for trees modeling circular means, we suggest a distributional approach for both trees and forests yielding probabilistic forecasts based on the von Mises distribution. The resulting tree-based models simplify the estimation process by using the available covariates for partitioning the data into sufficiently homogeneous subgroups so that a simple von Mises distribution without further covariates can be fitted to the circular response in each subgroup. These circular regression trees are straightforward to interpret, can capture nonlinear effects and interactions, and automatically select the relevant covariates that are associated with either location and/or scale changes in the von Mises distribution. Combining an ensemble of circular regression trees to a circular regression forest yields a local adaptive likelihood estimator for the von Mises distribution that can regularize and smooth the covariate effects. The new methods are evaluated in a case study on probabilistic wind direction forecasting at two Austrian airports, considering other common approaches as a benchmark.},
  version = {1},
  keywords = {FOS: Computer and information sciences,Methodology (stat.ME)}
}

@article{ledig2016,
  title = {Photo-{{Realistic Single Image Super-Resolution Using}} a {{Generative Adversarial Network}}},
  author = {Ledig, Christian and Theis, Lucas and Huszar, Ferenc and Caballero, Jose and Cunningham, Andrew and Acosta, Alejandro and Aitken, Andrew and Tejani, Alykhan and Totz, Johannes and Wang, Zehan and Shi, Wenzhe},
  date = {2016},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1609.04802},
  url = {https://arxiv.org/abs/1609.04802},
  urldate = {2023-07-10},
  abstract = {Despite the breakthroughs in accuracy and speed of single image super-resolution using faster and deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover the finer texture details when we super-resolve at large upscaling factors? The behavior of optimization-based super-resolution methods is principally driven by the choice of the objective function. Recent work has largely focused on minimizing the mean squared reconstruction error. The resulting estimates have high peak signal-to-noise ratios, but they are often lacking high-frequency details and are perceptually unsatisfying in the sense that they fail to match the fidelity expected at the higher resolution. In this paper, we present SRGAN, a generative adversarial network (GAN) for image super-resolution (SR). To our knowledge, it is the first framework capable of inferring photo-realistic natural images for 4x upscaling factors. To achieve this, we propose a perceptual loss function which consists of an adversarial loss and a content loss. The adversarial loss pushes our solution to the natural image manifold using a discriminator network that is trained to differentiate between the super-resolved images and original photo-realistic images. In addition, we use a content loss motivated by perceptual similarity instead of similarity in pixel space. Our deep residual network is able to recover photo-realistic textures from heavily downsampled images on public benchmarks. An extensive mean-opinion-score (MOS) test shows hugely significant gains in perceptual quality using SRGAN. The MOS scores obtained with SRGAN are closer to those of the original high-resolution images than to those obtained with any state-of-the-art method.},
  version = {5},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),Machine Learning (stat.ML),read,reviewed},
  file = {/Users/luca/Documents/literature/zotero/ledig2016.pdf}
}

@article{liang2021,
  title = {{{SwinIR}}: {{Image Restoration Using Swin Transformer}}},
  shorttitle = {{{SwinIR}}},
  author = {Liang, Jingyun and Cao, Jiezhang and Sun, Guolei and Zhang, Kai and Van Gool, Luc and Timofte, Radu},
  date = {2021},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2108.10257},
  url = {https://arxiv.org/abs/2108.10257},
  urldate = {2023-11-30},
  abstract = {Image restoration is a long-standing low-level vision problem that aims to restore high-quality images from low-quality images (e.g., downscaled, noisy and compressed images). While state-of-the-art image restoration methods are based on convolutional neural networks, few attempts have been made with Transformers which show impressive performance on high-level vision tasks. In this paper, we propose a strong baseline model SwinIR for image restoration based on the Swin Transformer. SwinIR consists of three parts: shallow feature extraction, deep feature extraction and high-quality image reconstruction. In particular, the deep feature extraction module is composed of several residual Swin Transformer blocks (RSTB), each of which has several Swin Transformer layers together with a residual connection. We conduct experiments on three representative tasks: image super-resolution (including classical, lightweight and real-world image super-resolution), image denoising (including grayscale and color image denoising) and JPEG compression artifact reduction. Experimental results demonstrate that SwinIR outperforms state-of-the-art methods on different tasks by \$\textbackslash textbf\{up to 0.14\$\textbackslash sim\$0.45dB\}\$, while the total number of parameters can be reduced by \$\textbackslash textbf\{up to 67\%\}\$.},
  version = {1},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Electrical engineering electronic engineering information engineering,Image and Video Processing (eess.IV),new},
  file = {/Users/luca/Documents/literature/zotero/liang2021.pdf}
}

@article{lin2013,
  title = {Network {{In Network}}},
  author = {Lin, Min and Chen, Qiang and Yan, Shuicheng},
  date = {2013},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1312.4400},
  url = {https://arxiv.org/abs/1312.4400},
  urldate = {2023-05-15},
  abstract = {We propose a novel deep network structure called "Network In Network" (NIN) to enhance model discriminability for local patches within the receptive field. The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input. Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field. We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator. The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer. Deep NIN can be implemented by stacking mutiple of the above described structure. With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers. We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets.},
  version = {3},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),Machine Learning (cs.LG),Neural and Evolutionary Computing (cs.NE),new},
  file = {/Users/luca/Documents/literature/zotero/lin2013.pdf}
}

@inproceedings{lin2023,
  title = {Speech {{Modeling}} with a {{Hierarchical Transformer Dynamical VAE}}},
  booktitle = {{{ICASSP}} 2023 - 2023 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Lin, Xiaoyu and Bie, Xiaoyu and Leglaive, Simon and Girin, Laurent and Alameda-Pineda, Xavier},
  date = {2023-06-04},
  pages = {1--5},
  publisher = {IEEE},
  location = {Rhodes Island, Greece},
  doi = {10.1109/ICASSP49357.2023.10096751},
  url = {https://ieeexplore.ieee.org/document/10096751/},
  urldate = {2023-06-21},
  eventtitle = {{{ICASSP}} 2023 - 2023 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  isbn = {978-1-72816-327-7},
  keywords = {new},
  file = {/Users/luca/Documents/literature/zotero/lin2023.pdf}
}

@inproceedings{liu2019,
  title = {Universal {{Adversarial Perturbation}} via {{Prior Driven Uncertainty Approximation}}},
  booktitle = {2019 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Liu, Hong and Ji, Rongrong and Li, Jie and Zhang, Baochang and Gao, Yue and Wu, Yongjian and Huang, Feiyue},
  date = {2019-10},
  pages = {2941--2949},
  publisher = {IEEE},
  location = {Seoul, Korea (South)},
  doi = {10.1109/ICCV.2019.00303},
  url = {https://ieeexplore.ieee.org/document/9008259/},
  urldate = {2024-03-12},
  eventtitle = {2019 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})},
  isbn = {978-1-72814-803-8},
  file = {/Users/luca/Documents/literature/zotero/liu2019.pdf}
}

@article{lyu2019,
  title = {{{MRI Super-Resolution}} with {{Ensemble Learning}} and {{Complementary Priors}}},
  author = {Lyu, Qing and Shan, Hongming and Wang, Ge},
  date = {2019},
  publisher = {[object Object]},
  doi = {10.48550/ARXIV.1907.03063},
  url = {https://arxiv.org/abs/1907.03063},
  urldate = {2024-04-01},
  abstract = {Magnetic resonance imaging (MRI) is a widely used medical imaging modality. However, due to the limitations in hardware, scan time, and throughput, it is often clinically challenging to obtain high-quality MR images. The super-resolution approach is potentially promising to improve MR image quality without any hardware upgrade. In this paper, we propose an ensemble learning and deep learning framework for MR image super-resolution. In our study, we first enlarged low resolution images using 5 commonly used super-resolution algorithms and obtained differentially enlarged image datasets with complementary priors. Then, a generative adversarial network (GAN) is trained with each dataset to generate super-resolution MR images. Finally, a convolutional neural network is used for ensemble learning that synergizes the outputs of GANs into the final MR super-resolution images. According to our results, the ensemble learning results outcome any one of GAN outputs. Compared with some state-of-the-art deep learning-based super-resolution methods, our approach is advantageous in suppressing artifacts and keeping more image details.},
  version = {1},
  keywords = {FOS: Computer and information sciences,FOS: Electrical engineering electronic engineering information engineering,FOS: Physical sciences,Image and Video Processing (eess.IV),Machine Learning (cs.LG),Medical Physics (physics.med-ph)},
  file = {/Users/luca/Documents/literature/zotero/lyu2019.pdf}
}

@article{mao2016,
  title = {Least {{Squares Generative Adversarial Networks}}},
  author = {Mao, Xudong and Li, Qing and Xie, Haoran and Lau, Raymond Y. K. and Wang, Zhen and Smolley, Stephen Paul},
  date = {2016},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1611.04076},
  url = {https://arxiv.org/abs/1611.04076},
  urldate = {2023-07-20},
  abstract = {Unsupervised learning with generative adversarial networks (GANs) has proven hugely successful. Regular GANs hypothesize the discriminator as a classifier with the sigmoid cross entropy loss function. However, we found that this loss function may lead to the vanishing gradients problem during the learning process. To overcome such a problem, we propose in this paper the Least Squares Generative Adversarial Networks (LSGANs) which adopt the least squares loss function for the discriminator. We show that minimizing the objective function of LSGAN yields minimizing the Pearson \$χ\textasciicircum 2\$ divergence. There are two benefits of LSGANs over regular GANs. First, LSGANs are able to generate higher quality images than regular GANs. Second, LSGANs perform more stable during the learning process. We evaluate LSGANs on five scene datasets and the experimental results show that the images generated by LSGANs are of better quality than the ones generated by regular GANs. We also conduct two comparison experiments between LSGANs and regular GANs to illustrate the stability of LSGANs.},
  version = {3},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),in progress}
}

@article{mardia1999,
  title = {Directional Statistics and Shape Analysis},
  author = {Mardia, K. V.},
  date = {1999-12},
  journaltitle = {Journal of Applied Statistics},
  shortjournal = {Journal of Applied Statistics},
  volume = {26},
  number = {8},
  pages = {949--957},
  issn = {0266-4763, 1360-0532},
  doi = {10.1080/02664769921954},
  url = {http://www.tandfonline.com/doi/abs/10.1080/02664769921954},
  urldate = {2023-08-27},
  langid = {english},
  keywords = {new},
  file = {/Users/luca/Documents/literature/zotero/mardia1999.pdf}
}

@book{mardia2000,
  title = {Directional Statistics},
  author = {Mardia, K. V. and Jupp, Peter E.},
  date = {2000},
  series = {Wiley Series in Probability and Statistics},
  publisher = {J. Wiley},
  location = {Chichester ; New York},
  isbn = {978-0-471-95333-3},
  pagetotal = {429},
  keywords = {Distribution (Probability theory),in progress,Mathematical statistics,Sampling (Statistics)},
  file = {/Users/luca/Documents/literature/zotero/mardia2000.pdf}
}

@article{marquez2019,
  title = {Neuroimaging {{Biomarkers}} for {{Alzheimer}}’s {{Disease}}},
  author = {Márquez, Freddie and Yassa, Michael A.},
  date = {2019-12},
  journaltitle = {Molecular Neurodegeneration},
  shortjournal = {Mol Neurodegeneration},
  volume = {14},
  number = {1},
  pages = {21},
  issn = {1750-1326},
  doi = {10.1186/s13024-019-0325-5},
  url = {https://molecularneurodegeneration.biomedcentral.com/articles/10.1186/s13024-019-0325-5},
  urldate = {2023-11-13},
  langid = {english},
  keywords = {new},
  file = {/Users/luca/Documents/literature/zotero/marquez2019.pdf}
}

@article{masuyama2019,
  title = {Deep {{Griffin-Lim Iteration}}},
  author = {Masuyama, Yoshiki and Yatabe, Kohei and Koizumi, Yuma and Oikawa, Yasuhiro and Harada, Noboru},
  date = {2019},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1903.03971},
  url = {https://arxiv.org/abs/1903.03971},
  urldate = {2023-07-25},
  abstract = {This paper presents a novel phase reconstruction method (only from a given amplitude spectrogram) by combining a signal-processing-based approach and a deep neural network (DNN). To retrieve a time-domain signal from its amplitude spectrogram, the corresponding phase is required. One of the popular phase reconstruction methods is the Griffin-Lim algorithm (GLA), which is based on the redundancy of the short-time Fourier transform. However, GLA often involves many iterations and produces low-quality signals owing to the lack of prior knowledge of the target signal. In order to address these issues, in this study, we propose an architecture which stacks a sub-block including two GLA-inspired fixed layers and a DNN. The number of stacked sub-blocks is adjustable, and we can trade the performance and computational load based on requirements of applications. The effectiveness of the proposed method is investigated by reconstructing phases from amplitude spectrograms of speeches.},
  version = {1},
  keywords = {Audio and Speech Processing (eess.AS),FOS: Electrical engineering electronic engineering information engineering,Machine Learning (cs.LG),read,Sound (cs.SD)},
  file = {/Users/luca/Documents/literature/zotero/masuyama2019.pdf}
}

@inproceedings{masuyama2020,
  title = {Phase {{Reconstruction Based On Recurrent Phase Unwrapping With Deep Neural Networks}}},
  booktitle = {{{ICASSP}} 2020 - 2020 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Masuyama, Yoshiki and Yatabe, Kohei and Koizumi, Yuma and Oikawa, Yasuhiro and Harada, Noboru},
  date = {2020-05},
  pages = {826--830},
  publisher = {IEEE},
  location = {Barcelona, Spain},
  doi = {10.1109/ICASSP40776.2020.9053234},
  url = {https://ieeexplore.ieee.org/document/9053234/},
  urldate = {2023-08-29},
  eventtitle = {{{ICASSP}} 2020 - 2020 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  isbn = {978-1-5090-6631-5},
  keywords = {read},
  file = {/Users/luca/Documents/literature/zotero/masuyama2020.pdf}
}

@article{masuyama2021,
  title = {Deep {{Griffin}}–{{Lim Iteration}}: {{Trainable Iterative Phase Reconstruction Using Neural Network}}},
  shorttitle = {Deep {{Griffin}}–{{Lim Iteration}}},
  author = {Masuyama, Yoshiki and Yatabe, Kohei and Koizumi, Yuma and Oikawa, Yasuhiro and Harada, Noboru},
  date = {2021-01},
  journaltitle = {IEEE Journal of Selected Topics in Signal Processing},
  shortjournal = {IEEE J. Sel. Top. Signal Process.},
  volume = {15},
  number = {1},
  pages = {37--50},
  issn = {1932-4553, 1941-0484},
  doi = {10.1109/JSTSP.2020.3034486},
  url = {https://ieeexplore.ieee.org/document/9242279/},
  urldate = {2023-07-26},
  keywords = {read},
  file = {/Users/luca/Documents/literature/zotero/masuyama2021.pdf}
}

@article{mcclure2016,
  title = {Robustly Representing Uncertainty in Deep Neural Networks through Sampling},
  author = {McClure, Patrick and Kriegeskorte, Nikolaus},
  date = {2016},
  publisher = {[object Object]},
  doi = {10.48550/ARXIV.1611.01639},
  url = {https://arxiv.org/abs/1611.01639},
  urldate = {2024-05-10},
  abstract = {As deep neural networks (DNNs) are applied to increasingly challenging problems, they will need to be able to represent their own uncertainty. Modeling uncertainty is one of the key features of Bayesian methods. Using Bernoulli dropout with sampling at prediction time has recently been proposed as an efficient and well performing variational inference method for DNNs. However, sampling from other multiplicative noise based variational distributions has not been investigated in depth. We evaluated Bayesian DNNs trained with Bernoulli or Gaussian multiplicative masking of either the units (dropout) or the weights (dropconnect). We tested the calibration of the probabilistic predictions of Bayesian convolutional neural networks (CNNs) on MNIST and CIFAR-10. Sampling at prediction time increased the calibration of the DNNs' probabalistic predictions. Sampling weights, whether Gaussian or Bernoulli, led to more robust representation of uncertainty compared to sampling of units. However, using either Gaussian or Bernoulli dropout led to increased test set classification accuracy. Based on these findings we used both Bernoulli dropout and Gaussian dropconnect concurrently, which we show approximates the use of a spike-and-slab variational distribution without increasing the number of learned parameters. We found that spike-and-slab sampling had higher test set performance than Gaussian dropconnect and more robustly represented its uncertainty compared to Bernoulli dropout.},
  version = {7},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Biological sciences,FOS: Computer and information sciences,Machine Learning (cs.LG),Neural and Evolutionary Computing (cs.NE),Neurons and Cognition (q-bio.NC)},
  file = {/Users/luca/Documents/literature/zotero/mcclure2016.pdf}
}

@article{minaee2020,
  title = {Image {{Segmentation Using Deep Learning}}: {{A Survey}}},
  shorttitle = {Image {{Segmentation Using Deep Learning}}},
  author = {Minaee, Shervin and Boykov, Yuri and Porikli, Fatih and Plaza, Antonio and Kehtarnavaz, Nasser and Terzopoulos, Demetri},
  date = {2020},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2001.05566},
  url = {https://arxiv.org/abs/2001.05566},
  urldate = {2023-11-30},
  abstract = {Image segmentation is a key topic in image processing and computer vision with applications such as scene understanding, medical image analysis, robotic perception, video surveillance, augmented reality, and image compression, among many others. Various algorithms for image segmentation have been developed in the literature. Recently, due to the success of deep learning models in a wide range of vision applications, there has been a substantial amount of works aimed at developing image segmentation approaches using deep learning models. In this survey, we provide a comprehensive review of the literature at the time of this writing, covering a broad spectrum of pioneering works for semantic and instance-level segmentation, including fully convolutional pixel-labeling networks, encoder-decoder architectures, multi-scale and pyramid based approaches, recurrent networks, visual attention models, and generative models in adversarial settings. We investigate the similarity, strengths and challenges of these deep learning models, examine the most widely used datasets, report performances, and discuss promising future research directions in this area.},
  version = {5},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,Machine Learning (cs.LG),new},
  file = {/Users/luca/Documents/literature/zotero/minaee2020.pdf}
}

@article{moca2021,
  title = {Time-Frequency Super-Resolution with Superlets},
  author = {Moca, Vasile V. and Bârzan, Harald and Nagy-Dăbâcan, Adriana and Mureșan, Raul C.},
  date = {2021-01-12},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {12},
  number = {1},
  pages = {337},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-20539-9},
  url = {https://www.nature.com/articles/s41467-020-20539-9},
  urldate = {2023-10-30},
  abstract = {Abstract             Due to the Heisenberg–Gabor uncertainty principle, finite oscillation transients are difficult to localize simultaneously in both time and frequency. Classical estimators, like the short-time Fourier transform or the continuous-wavelet transform optimize either temporal or frequency resolution, or find a suboptimal tradeoff. Here, we introduce a spectral estimator enabling time-frequency super-resolution, called superlet, that uses sets of wavelets with increasingly constrained bandwidth. These are combined geometrically in order to maintain the good temporal resolution of single wavelets and gain frequency resolution in upper bands. The normalization of wavelets in the set facilitates exploration of data with scale-free, fractal nature, containing oscillation packets that are self-similar across frequencies. Superlets perform well on synthetic data and brain signals recorded in humans and rodents, resolving high frequency bursts with excellent precision. Importantly, they can reveal fast transient oscillation events in single trials that may be hidden in the averaged time-frequency spectrum by other methods.},
  langid = {english},
  file = {/Users/luca/Documents/literature/zotero/moca2021.pdf}
}

@article{mok2020,
  title = {Fast {{Symmetric Diffeomorphic Image Registration}} with {{Convolutional Neural Networks}}},
  author = {Mok, Tony C. W. and Chung, Albert C. S.},
  date = {2020},
  publisher = {[object Object]},
  doi = {10.48550/ARXIV.2003.09514},
  url = {https://arxiv.org/abs/2003.09514},
  urldate = {2024-05-12},
  abstract = {Diffeomorphic deformable image registration is crucial in many medical image studies, as it offers unique, special properties including topology preservation and invertibility of the transformation. Recent deep learning-based deformable image registration methods achieve fast image registration by leveraging a convolutional neural network (CNN) to learn the spatial transformation from the synthetic ground truth or the similarity metric. However, these approaches often ignore the topology preservation of the transformation and the smoothness of the transformation which is enforced by a global smoothing energy function alone. Moreover, deep learning-based approaches often estimate the displacement field directly, which cannot guarantee the existence of the inverse transformation. In this paper, we present a novel, efficient unsupervised symmetric image registration method which maximizes the similarity between images within the space of diffeomorphic maps and estimates both forward and inverse transformations simultaneously. We evaluate our method on 3D image registration with a large scale brain image dataset. Our method achieves state-of-the-art registration accuracy and running time while maintaining desirable diffeomorphic properties.},
  version = {3},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences},
  file = {/Users/luca/Documents/literature/zotero/mok2020.pdf}
}

@article{montag2018,
  title = {Affective {{Neuroscience Theory}} and {{Personality}}: {{An Update}}},
  shorttitle = {Affective {{Neuroscience Theory}} and {{Personality}}},
  author = {Montag, Christian and Davis, Kenneth L.},
  date = {2018-08-10},
  journaltitle = {Personality Neuroscience},
  shortjournal = {Personality Neuroscience},
  volume = {1},
  pages = {e12},
  issn = {2513-9886},
  doi = {10.1017/pen.2018.10},
  url = {https://www.cambridge.org/core/product/identifier/S251398861800010X/type/journal_article},
  urldate = {2024-03-11},
  abstract = {Abstract                            The present work gives a short overview of central aspects of Jaak Panksepp’s               Affective Neuroscience Theory               (AN theory) and its relevance for modern personality neuroscience. In contrast to the widely used Big Five approach to studying and understanding human personality, AN theory provides researchers with a distinct roadmap to the biological basis of personality, including molecular and neuroanatomical candidates, to understand individual differences in human behavior. Such molecular and neuroanatomical brain candidates have been derived by means of electrical brain stimulation and pharmacological challenges, while investigating primary emotional systems anchored in the subcortical mammalian brain. Research results derived from the study of emotions in mammals are also of relevance for humans because ancient layers of our minds—those layers where primary emotions originate—have been homologously conserved across species. From an evolutionary perspective, this makes sense because primal emotions represent “built-in tools for survival” for all mammals. In this context, Montag and Panksepp recently illustrated a potential ancient neurobiological effect by carving out robust associations between individual differences in primary emotions (assessed via self-report) and the Big Five in a cross-cultural study with data from the United States, Germany, and China. These associations together with some ideas derived from MacLean’s Triune Brain concept highlighted (a) that primary emotions likely represent the phylogenetically oldest parts of human personality and (b) that primary emotions influence human personality in a bottom-up fashion given their localization in ancient subcortical brain regions. A comment on the work by Montag and Panksepp asked for insights on putative links between primary emotions and facets of the Big Five. Therefore, we provide some first insights into such associations from recent Germany data. In addition, the present work provides a new short version of the Affective Neuroscience Personality Scales to assess individual differences in primary emotions.},
  langid = {english},
  file = {/Users/luca/Documents/literature/zotero/montag2018.pdf}
}

@book{murphy2022,
  title = {Probabilistic Machine Learning: An Introduction},
  shorttitle = {Probabilistic Machine Learning},
  author = {Murphy, Kevin P.},
  date = {2022},
  series = {Adaptive Computation and Machine Learning Series},
  publisher = {The MIT Press},
  location = {Cambridge, Massachusetts},
  abstract = {"This book provides a detailed and up-to-date coverage of machine learning. It is unique in that it unifies approaches based on deep learning with approaches based on probabilistic modeling and inference. It provides mathematical background (e.g. linear algebra, optimization), basic topics (e.g., linear and logistic regression, deep neural networks), as well as more advanced topics (e.g., Gaussian processes). It provides a perfect introduction for people who want to understand cutting edge work in top machine learning conferences such as NeurIPS, ICML and ICLR"--},
  isbn = {978-0-262-04682-4},
  pagetotal = {826},
  keywords = {in progress,Machine learning,Probabilities},
  file = {/Users/luca/Documents/literature/zotero/murphy2022.pdf}
}

@book{murphy2022a,
  title = {Machine Learning: A Probabilistic Perspective},
  shorttitle = {Machine Learning},
  author = {Murphy, Kevin P.},
  date = {2022},
  edition = {2nd ed},
  publisher = {MIT Press},
  location = {Cambridge, MA},
  isbn = {978-0-262-04466-0},
  langid = {english},
  keywords = {new},
  annotation = {OCLC: 1255636989},
  file = {/Users/luca/Documents/literature/zotero/murphy2022a.pdf}
}

@book{murphy2023,
  title = {Probabilistic {{Machine Learning}}: {{Advanced Topics}}},
  author = {Murphy, Kevin P.},
  date = {2023},
  edition = {1},
  volume = {1},
  publisher = {MIT Press},
  url = {http://probml.github.io/book2},
  keywords = {new},
  file = {/Users/luca/Documents/literature/zotero/murphy2023.pdf}
}

@inproceedings{nabney1995,
  title = {Modelling Conditional Probability Distributions for Periodic Variables},
  booktitle = {4th {{International Conference}} on {{Artificial Neural Networks}}},
  author = {Nabney, I.T.},
  date = {1995},
  volume = {1995},
  pages = {177--182},
  publisher = {IEE},
  location = {Cambridge, UK},
  doi = {10.1049/cp:19950550},
  eventtitle = {4th {{International Conference}} on {{Artificial Neural Networks}}},
  isbn = {978-0-85296-641-9},
  langid = {english},
  keywords = {in progress},
  file = {/Users/luca/Documents/literature/zotero/nabney12.pdf;/Users/luca/Documents/literature/zotero/nabney1995.pdf}
}

@inproceedings{natsiou2021,
  title = {A Sinusoidal Signal Reconstruction Method for the Inversion of the Mel-Spectrogram},
  booktitle = {2021 {{IEEE International Symposium}} on {{Multimedia}} ({{ISM}})},
  author = {Natsiou, Anastasia and O'Leary, Sean},
  date = {2021-11},
  pages = {245--248},
  publisher = {IEEE},
  location = {Naple, Italy},
  doi = {10.1109/ISM52913.2021.00048},
  url = {https://ieeexplore.ieee.org/document/9665798/},
  urldate = {2023-07-31},
  eventtitle = {2021 {{IEEE International Symposium}} on {{Multimedia}} ({{ISM}})},
  isbn = {978-1-66543-734-9},
  keywords = {read},
  file = {/Users/luca/Documents/literature/zotero/natsiou2021.pdf}
}

@thesis{navarro2022,
  title = {Probabilistic {{Machine Learning}} for {{Circular Statistics}}},
  author = {Navarro, Alexandre},
  date = {2022},
  keywords = {in progress},
  file = {/Users/luca/Documents/literature/zotero/navarro2022.pdf}
}

@article{nenov2023,
  title = {Faster than {{Fast}}: {{Accelerating}} the {{Griffin-Lim Algorithm}}},
  shorttitle = {Faster than {{Fast}}},
  author = {Nenov, Rossen and Nguyen, Dang-Khoa and Balazs, Peter},
  date = {2023},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2304.12905},
  url = {https://arxiv.org/abs/2304.12905},
  urldate = {2023-09-18},
  abstract = {The phase retrieval problem is found in various areas of applications of engineering and applied physics. It is also a very active field of research in mathematics, signal processing and machine learning. In this paper, we present an accelerated version of the well known Fast Griffin-Lim algorithm (FGLA) for the phase retrieval problem in a general setting. It has increased the speed of convergence, and most importantly, the limit points of the generated sequence can reach a significantly smaller error than the ones generated by FGLA. We will give a motivation of the acceleration and compare it numerically to its predecessors and other algorithms typically used to solve similar problems.},
  version = {1},
  keywords = {90C26,FOS: Mathematics,Optimization and Control (math.OC),read},
  file = {/Users/luca/Documents/literature/zotero/nenov2023.pdf}
}

@article{nguyen2022,
  title = {Self-{{Supervised Super-Resolution}} for {{Multi-Exposure Push-Frame Satellites}}},
  author = {Nguyen, Ngoc Long and Anger, Jérémy and Davy, Axel and Arias, Pablo and Facciolo, Gabriele},
  date = {2022},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2205.02031},
  url = {https://arxiv.org/abs/2205.02031},
  urldate = {2023-11-30},
  abstract = {Modern Earth observation satellites capture multi-exposure bursts of push-frame images that can be super-resolved via computational means. In this work, we propose a super-resolution method for such multi-exposure sequences, a problem that has received very little attention in the literature. The proposed method can handle the signal-dependent noise in the inputs, process sequences of any length, and be robust to inaccuracies in the exposure times. Furthermore, it can be trained end-to-end with self-supervision, without requiring ground truth high resolution frames, which makes it especially suited to handle real data. Central to our method are three key contributions: i) a base-detail decomposition for handling errors in the exposure times, ii) a noise-level-aware feature encoding for improved fusion of frames with varying signal-to-noise ratio and iii) a permutation invariant fusion strategy by temporal pooling operators. We evaluate the proposed method on synthetic and real data and show that it outperforms by a significant margin existing single-exposure approaches that we adapted to the multi-exposure case.},
  version = {1},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Electrical engineering electronic engineering information engineering,Image and Video Processing (eess.IV),new},
  file = {/Users/luca/Documents/literature/zotero/nguyen2022.pdf}
}

@inproceedings{nix1994,
  title = {Estimating the Mean and Variance of the Target Probability Distribution},
  booktitle = {Proceedings of 1994 {{IEEE International Conference}} on {{Neural Networks}} ({{ICNN}}'94)},
  author = {Nix, D.A. and Weigend, A.S.},
  date = {1994},
  pages = {55-60 vol.1},
  publisher = {IEEE},
  location = {Orlando, FL, USA},
  doi = {10.1109/ICNN.1994.374138},
  url = {http://ieeexplore.ieee.org/document/374138/},
  urldate = {2023-09-21},
  eventtitle = {Proceedings of 1994 {{IEEE International Conference}} on {{Neural Networks}} ({{ICNN}}'94)},
  isbn = {978-0-7803-1901-1},
  keywords = {new},
  file = {/Users/luca/Documents/literature/zotero/nix1994.pdf}
}

@inproceedings{nugraha2019,
  title = {A {{Deep Generative Model}} of {{Speech Complex Spectrograms}}},
  booktitle = {{{ICASSP}} 2019 - 2019 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Nugraha, Aditya Arie and Sekiguchi, Kouhei and Yoshii, Kazuyoshi},
  date = {2019-05},
  pages = {905--909},
  publisher = {IEEE},
  location = {Brighton, United Kingdom},
  doi = {10.1109/ICASSP.2019.8682797},
  url = {https://ieeexplore.ieee.org/document/8682797/},
  urldate = {2023-05-23},
  eventtitle = {{{ICASSP}} 2019 - 2019 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  isbn = {978-1-4799-8131-1},
  keywords = {read},
  file = {/Users/luca/Documents/literature/zotero/nugraha2019.pdf}
}

@article{oord2016,
  title = {{{WaveNet}}: {{A Generative Model}} for {{Raw Audio}}},
  shorttitle = {{{WaveNet}}},
  author = {family=Oord, given=Aaron, prefix=van den, useprefix=false and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
  date = {2016},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1609.03499},
  url = {https://arxiv.org/abs/1609.03499},
  urldate = {2023-09-18},
  abstract = {This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
  version = {2},
  keywords = {FOS: Computer and information sciences,Machine Learning (cs.LG),Sound (cs.SD)},
  file = {/Users/luca/Documents/literature/zotero/oord2016.pdf}
}

@article{oord2017,
  title = {Neural {{Discrete Representation Learning}}},
  author = {family=Oord, given=Aaron, prefix=van den, useprefix=false and Vinyals, Oriol and Kavukcuoglu, Koray},
  date = {2017},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1711.00937},
  url = {https://arxiv.org/abs/1711.00937},
  urldate = {2023-11-17},
  abstract = {Learning useful representations without supervision remains a key challenge in machine learning. In this paper, we propose a simple yet powerful generative model that learns such discrete representations. Our model, the Vector Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: the encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static. In order to learn a discrete latent representation, we incorporate ideas from vector quantisation (VQ). Using the VQ method allows the model to circumvent issues of "posterior collapse" -- where the latents are ignored when they are paired with a powerful autoregressive decoder -- typically observed in the VAE framework. Pairing these representations with an autoregressive prior, the model can generate high quality images, videos, and speech as well as doing high quality speaker conversion and unsupervised learning of phonemes, providing further evidence of the utility of the learnt representations.},
  version = {2},
  keywords = {FOS: Computer and information sciences,Machine Learning (cs.LG),new},
  file = {/Users/luca/Documents/literature/zotero/oord2017.pdf}
}

@book{oppenheim1975,
  title = {Digital Signal Processing},
  author = {Oppenheim, Alan V. and Schafer, Ronald W.},
  date = {1975},
  publisher = {Prentice-Hall},
  location = {Englewood Cliffs, N.J},
  isbn = {978-0-13-214635-7},
  pagetotal = {585},
  keywords = {Digital electronics,in progress,Signal theory (Telecommunication)},
  file = {/Users/luca/Documents/literature/zotero/oppenheim1975.pdf}
}

@article{oppenheim1981,
  title = {The Importance of Phase in Signals},
  author = {Oppenheim, A.V. and Lim, J.S.},
  date = {1981},
  journaltitle = {Proceedings of the IEEE},
  shortjournal = {Proc. IEEE},
  volume = {69},
  number = {5},
  pages = {529--541},
  issn = {0018-9219},
  doi = {10.1109/PROC.1981.12022},
  url = {http://ieeexplore.ieee.org/document/1456290/},
  urldate = {2023-08-26},
  keywords = {in progress},
  file = {/Users/luca/Documents/literature/zotero/oppenheim1981.pdf}
}

@article{osadebey2019,
  title = {Local {{Indicators}} of {{Spatial Autocorrelation}} ({{LISA}}): {{Application}} to {{Blind Noise-Based Perceptual Quality Metric Index}} for {{Magnetic Resonance Images}}},
  shorttitle = {Local {{Indicators}} of {{Spatial Autocorrelation}} ({{LISA}})},
  author = {Osadebey, Michael and Pedersen, Marius and Arnold, Douglas and Wendel-Mitoraj, Katrina},
  date = {2019-01-15},
  journaltitle = {Journal of Imaging},
  shortjournal = {J. Imaging},
  volume = {5},
  number = {1},
  pages = {20},
  issn = {2313-433X},
  doi = {10.3390/jimaging5010020},
  url = {http://www.mdpi.com/2313-433X/5/1/20},
  urldate = {2023-11-01},
  abstract = {Noise-based quality evaluation of MRI images is highly desired in noise-dominant environments. Current noise-based MRI quality evaluation methods have drawbacks which limit their effective performance. Traditional full-reference methods such as SNR and most of the model-based techniques cannot provide perceptual quality metrics required for accurate diagnosis, treatment and monitoring of diseases. Although techniques based on the Moran coefficients are perceptual quality metrics, they are full-reference methods and will be ineffective in applications where the reference image is not available. Furthermore, the predicted quality scores are difficult to interpret because their quality indices are not standardized. In this paper, we propose a new no-reference perceptual quality evaluation method for grayscale images such as MRI images. Our approach is formulated to mimic how humans perceive an image. It transforms noise level into a standardized perceptual quality score. Global Moran statistics is combined with local indicators of spatial autocorrelation in the form of local Moran statistics. Quality score is predicted from perceptually weighted combination of clustered and random pixels. Performance evaluation, comparative performance evaluation and validation by human observers, shows that the proposed method will be a useful tool in the evaluation of retrospectively acquired MRI images and the evaluation of noise reduction algorithms.},
  langid = {english},
  keywords = {new},
  file = {/Users/luca/Documents/literature/zotero/osadebey2019.pdf}
}

@article{oyamada2018,
  title = {Generative Adversarial Network-Based Approach to Signal Reconstruction from Magnitude Spectrograms},
  author = {Oyamada, Keisuke and Kameoka, Hirokazu and Kaneko, Takuhiro and Tanaka, Kou and Hojo, Nobukatsu and Ando, Hiroyasu},
  date = {2018},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1804.02181},
  url = {https://arxiv.org/abs/1804.02181},
  urldate = {2023-07-09},
  abstract = {In this paper, we address the problem of reconstructing a time-domain signal (or a phase spectrogram) solely from a magnitude spectrogram. Since magnitude spectrograms do not contain phase information, we must restore or infer phase information to reconstruct a time-domain signal. One widely used approach for dealing with the signal reconstruction problem was proposed by Griffin and Lim. This method usually requires many iterations for the signal reconstruction process and depending on the inputs, it does not always produce high-quality audio signals. To overcome these shortcomings, we apply a learning-based approach to the signal reconstruction problem by modeling the signal reconstruction process using a deep neural network and training it using the idea of a generative adversarial network. Experimental evaluations revealed that our method was able to reconstruct signals faster with higher quality than the Griffin-Lim method.},
  version = {1},
  keywords = {FOS: Electrical engineering electronic engineering information engineering,Machine Learning (cs.LG),Machine Learning (stat.ML),read,Signal Processing (eess.SP)},
  file = {/Users/luca/Documents/literature/zotero/oyamada2018.pdf}
}

@article{panic2020,
  title = {{{MRI Reconstruction Using Markov Random Field}} and {{Total Variation}} as {{Composite Prior}}},
  author = {Panić, Marko and Jakovetić, Dušan and Vukobratović, Dejan and Crnojević, Vladimir and Pižurica, Aleksandra},
  date = {2020-06-03},
  journaltitle = {Sensors},
  shortjournal = {Sensors},
  volume = {20},
  number = {11},
  pages = {3185},
  issn = {1424-8220},
  doi = {10.3390/s20113185},
  url = {https://www.mdpi.com/1424-8220/20/11/3185},
  urldate = {2023-11-01},
  abstract = {Reconstruction of magnetic resonance images (MRI) benefits from incorporating a priori knowledge about statistical dependencies among the representation coefficients. Recent results demonstrate that modeling intraband dependencies with Markov Random Field (MRF) models enable superior reconstructions compared to inter-scale models. In this paper, we develop a novel reconstruction method, which includes a composite prior based on an MRF model and Total Variation (TV). We use an anisotropic MRF model and propose an original data-driven method for the adaptive estimation of its parameters. From a Bayesian perspective, we define a new position-dependent type of regularization and derive a compact reconstruction algorithm with a novel soft-thresholding rule. Experimental results show the effectiveness of this method compared to the state of the art in the field.},
  langid = {english},
  keywords = {new},
  file = {/Users/luca/Documents/literature/zotero/panic2020.pdf}
}

@article{patil2015,
  title = {Use of Baseband Phase Structure to Improve the Performance of Current Speech Enhancement Algorithms},
  author = {Patil, Sanjay P. and Gowdy, John N.},
  date = {2015-03},
  journaltitle = {Speech Communication},
  shortjournal = {Speech Communication},
  volume = {67},
  pages = {78--91},
  issn = {01676393},
  doi = {10.1016/j.specom.2014.11.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167639314000831},
  urldate = {2023-07-03},
  langid = {english},
  keywords = {read},
  file = {/Users/luca/Documents/literature/zotero/patil2015.pdf}
}

@article{peer2022,
  title = {Beyond {{Griffin-Lim}}: {{Improved Iterative Phase Retrieval}} for {{Speech}}},
  shorttitle = {Beyond {{Griffin-Lim}}},
  author = {Peer, Tal and Welker, Simon and Gerkmann, Timo},
  date = {2022},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2205.05496},
  url = {https://arxiv.org/abs/2205.05496},
  urldate = {2023-07-03},
  abstract = {Phase retrieval is a problem encountered not only in speech and audio processing, but in many other fields such as optics. Iterative algorithms based on non-convex set projections are effective and frequently used for retrieving the phase when only STFT magnitudes are available. While the basic Griffin-Lim algorithm and its variants have been the prevalent method for decades, more recent advances, e.g. in optics, raise the question: Can we do better than Griffin-Lim for speech signals, using the same principle of iterative projection? In this paper we compare the classical algorithms in the speech domain with two modern methods from optics with respect to reconstruction quality and convergence rate. Based on this study, we propose to combine Griffin-Lim with the Difference Map algorithm in a hybrid approach which shows superior results, in terms of both convergence and quality of the final reconstruction.},
  version = {1},
  keywords = {Audio and Speech Processing (eess.AS),FOS: Electrical engineering electronic engineering information engineering,read,Signal Processing (eess.SP),Sound (cs.SD)}
}

@inproceedings{peer2023,
  title = {{{DiffPhase}}: {{Generative Diffusion-Based STFT Phase Retrieval}}},
  shorttitle = {{{DiffPhase}}},
  booktitle = {{{ICASSP}} 2023 - 2023 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Peer, Tal and Welker, Simon and Gerkmann, Timo},
  date = {2023-06-04},
  pages = {1--5},
  publisher = {IEEE},
  location = {Rhodes Island, Greece},
  doi = {10.1109/ICASSP49357.2023.10095396},
  url = {https://ieeexplore.ieee.org/document/10095396/},
  urldate = {2023-07-03},
  eventtitle = {{{ICASSP}} 2023 - 2023 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  isbn = {978-1-72816-327-7},
  keywords = {read},
  file = {/Users/luca/Documents/literature/zotero/peer2023.pdf}
}

@article{pewsey2020,
  title = {Recent Advances in Directional Statistics},
  author = {Pewsey, Arthur and García-Portugués, Eduardo},
  date = {2020},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2005.06889},
  url = {https://arxiv.org/abs/2005.06889},
  urldate = {2023-08-28},
  abstract = {Mainstream statistical methodology is generally applicable to data observed in Euclidean space. There are, however, numerous contexts of considerable scientific interest in which the natural supports for the data under consideration are Riemannian manifolds like the unit circle, torus, sphere and their extensions. Typically, such data can be represented using one or more directions, and directional statistics is the branch of statistics that deals with their analysis. In this paper we provide a review of the many recent developments in the field since the publication of Mardia and Jupp (1999), still the most comprehensive text on directional statistics. Many of those developments have been stimulated by interesting applications in fields as diverse as astronomy, medicine, genetics, neurology, aeronautics, acoustics, image analysis, text mining, environmetrics, and machine learning. We begin by considering developments for the exploratory analysis of directional data before progressing to distributional models, general approaches to inference, hypothesis testing, regression, nonparametric curve estimation, methods for dimension reduction, classification and clustering, and the modelling of time series, spatial and spatio-temporal data. An overview of currently available software for analysing directional data is also provided, and potential future developments discussed.},
  version = {3},
  keywords = {62H11,FOS: Computer and information sciences,in progress,Methodology (stat.ME)},
  file = {/Users/luca/Documents/literature/zotero/pewsey2020.pdf}
}

@article{phuong2022,
  title = {Formal {{Algorithms}} for {{Transformers}}},
  author = {Phuong, Mary and Hutter, Marcus},
  date = {2022},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2207.09238},
  url = {https://arxiv.org/abs/2207.09238},
  urldate = {2023-05-15},
  abstract = {This document aims to be a self-contained, mathematically precise overview of transformer architectures and algorithms (*not* results). It covers what transformers are, how they are trained, what they are used for, their key architectural components, and a preview of the most prominent models. The reader is assumed to be familiar with basic ML terminology and simpler neural network architectures such as MLPs.},
  version = {1},
  keywords = {Artificial Intelligence (cs.AI),Computation and Language (cs.CL),Machine Learning (cs.LG),Neural and Evolutionary Computing (cs.NE),new},
  file = {/Users/luca/Documents/literature/zotero/phuong2022.pdf}
}

@online{preston2023,
  title = {Magnetic {{Resonance Imaging}} ({{MRI}}) of the {{Brain}} and {{Spine}}: {{Basics}}},
  author = {Preston, David C},
  date = {2023},
  url = {https://case.edu/med/neurology/NR/MRI%20Basics.htm#:~:text=T1%20(longitudinal%20relaxation%20time)%20is,with%20the%20external%20magnetic%20field.},
  urldate = {2023-10-23},
  langid = {english},
  keywords = {read}
}

@book{prince2023,
  title = {Understanding {{Deep Learning}}},
  author = {Prince, Simon},
  date = {2023},
  publisher = {MIT Press},
  keywords = {in progress},
  file = {/Users/luca/Documents/literature/zotero/prince22.pdf}
}

@article{purwins2019,
  title = {Deep {{Learning}} for {{Audio Signal Processing}}},
  author = {Purwins, Hendrik and Li, Bo and Virtanen, Tuomas and Schluter, Jan and Chang, Shuo-Yiin and Sainath, Tara},
  date = {2019-05},
  journaltitle = {IEEE Journal of Selected Topics in Signal Processing},
  shortjournal = {IEEE J. Sel. Top. Signal Process.},
  volume = {13},
  number = {2},
  pages = {206--219},
  issn = {1932-4553, 1941-0484},
  doi = {10.1109/JSTSP.2019.2908700},
  url = {https://ieeexplore.ieee.org/document/8678825/},
  urldate = {2023-07-31},
  keywords = {read},
  file = {/Users/luca/Documents/literature/zotero/purwins2019.pdf}
}

@book{puthusserypady2021,
  title = {Applied Signal Processing},
  editora = {Puthusserypady, Sadasivan},
  editoratype = {collaborator},
  date = {2021},
  publisher = {now, the essence of knowledge},
  location = {Hanover, MA, United States},
  isbn = {978-1-68083-979-1},
  langid = {english},
  annotation = {OCLC: 1249680177},
  file = {/Users/luca/Documents/literature/zotero/puthusserypady2021.pdf}
}

@article{rasmussen2019,
  title = {Alzheimer’s {{Disease}} – {{Why We Need Early Diagnosis}}},
  author = {Rasmussen, Jill and Langerman, Haya},
  date = {2019-12},
  journaltitle = {Degenerative Neurological and Neuromuscular Disease},
  shortjournal = {DNND},
  volume = {Volume 9},
  pages = {123--130},
  issn = {1179-9900},
  doi = {10.2147/DNND.S228939},
  url = {https://www.dovepress.com/alzheimers-disease-why-we-need-early-diagnosis-peer-reviewed-article-DNND},
  urldate = {2023-11-29},
  langid = {english},
  keywords = {new},
  file = {/Users/luca/Documents/literature/zotero/rasmussen2019.pdf}
}

@article{rezende2014,
  title = {Stochastic {{Backpropagation}} and {{Approximate Inference}} in {{Deep Generative Models}}},
  author = {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  date = {2014},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1401.4082},
  url = {https://arxiv.org/abs/1401.4082},
  urldate = {2023-05-17},
  abstract = {We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition model to represent approximate posterior distributions, and that acts as a stochastic encoder of the data. We develop stochastic back-propagation -- rules for back-propagation through stochastic variables -- and use this to develop an algorithm that allows for joint optimisation of the parameters of both the generative and recognition model. We demonstrate on several real-world data sets that the model generates realistic samples, provides accurate imputations of missing data and is a useful tool for high-dimensional data visualisation.},
  version = {3},
  keywords = {Artificial Intelligence (cs.AI),Computation (stat.CO),in progress,Machine Learning (cs.LG),Machine Learning (stat.ML),Methodology (stat.ME)},
  file = {/Users/luca/Documents/literature/zotero/rezende2014.pdf}
}

@article{richter2022,
  title = {Speech {{Enhancement}} and {{Dereverberation}} with {{Diffusion-based Generative Models}}},
  author = {Richter, Julius and Welker, Simon and Lemercier, Jean-Marie and Lay, Bunlong and Gerkmann, Timo},
  date = {2022},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2208.05830},
  url = {https://arxiv.org/abs/2208.05830},
  urldate = {2023-10-30},
  abstract = {In this work, we build upon our previous publication and use diffusion-based generative models for speech enhancement. We present a detailed overview of the diffusion process that is based on a stochastic differential equation and delve into an extensive theoretical examination of its implications. Opposed to usual conditional generation tasks, we do not start the reverse process from pure Gaussian noise but from a mixture of noisy speech and Gaussian noise. This matches our forward process which moves from clean speech to noisy speech by including a drift term. We show that this procedure enables using only 30 diffusion steps to generate high-quality clean speech estimates. By adapting the network architecture, we are able to significantly improve the speech enhancement performance, indicating that the network, rather than the formalism, was the main limitation of our original approach. In an extensive cross-dataset evaluation, we show that the improved method can compete with recent discriminative models and achieves better generalization when evaluating on a different corpus than used for training. We complement the results with an instrumental evaluation using real-world noisy recordings and a listening experiment, in which our proposed method is rated best. Examining different sampler configurations for solving the reverse process allows us to balance the performance and computational speed of the proposed method. Moreover, we show that the proposed method is also suitable for dereverberation and thus not limited to additive background noise removal. Code and audio examples are available online, see https://github.com/sp-uhh/sgmse},
  version = {2},
  keywords = {Audio and Speech Processing (eess.AS),FOS: Computer and information sciences,FOS: Electrical engineering electronic engineering information engineering,Machine Learning (cs.LG),new,Sound (cs.SD)},
  file = {/Users/luca/Documents/literature/zotero/richter2022.pdf}
}

@article{ronneberger2015,
  title = {U-{{Net}}: {{Convolutional Networks}} for {{Biomedical Image Segmentation}}},
  shorttitle = {U-{{Net}}},
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  date = {2015},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1505.04597},
  url = {https://arxiv.org/abs/1505.04597},
  urldate = {2023-11-29},
  abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
  version = {1},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,new},
  file = {/Users/luca/Documents/literature/zotero/ronneberger2015.pdf}
}

@book{rozanov1977,
  title = {Probability Theory: A Concise Course},
  shorttitle = {Probability Theory},
  author = {Rozanov, Jurij A.},
  editor = {Silverman, Richard A.},
  date = {1977},
  series = {Dover Books on Advanced Mathematics},
  edition = {Rev. engl. ed., unabr. and slightly corr. republ},
  publisher = {Dover Publ},
  location = {New York, NY},
  isbn = {978-0-486-63544-6},
  langid = {english},
  pagetotal = {148},
  keywords = {in progress},
  file = {/Users/luca/Documents/literature/zotero/rozanov1977.pdf}
}

@article{shin2024,
  title = {Super-Resolution Techniques for Biomedical Applications and Challenges},
  author = {Shin, Minwoo and Seo, Minjee and Lee, Kyunghyun and Yoon, Kyungho},
  date = {2024-03-19},
  journaltitle = {Biomedical Engineering Letters},
  shortjournal = {Biomed. Eng. Lett.},
  issn = {2093-9868, 2093-985X},
  doi = {10.1007/s13534-024-00365-4},
  url = {https://link.springer.com/10.1007/s13534-024-00365-4},
  urldate = {2024-03-25},
  langid = {english},
  file = {/Users/luca/Documents/literature/zotero/shin2024.pdf}
}

@report{simpson2023,
  title = {Grant {{Proposal}}},
  author = {Simpson, Ivor},
  date = {2023},
  file = {/Users/luca/Documents/literature/zotero/simpson2023.pdf}
}

@article{song2020,
  title = {Score-{{Based Generative Modeling}} through {{Stochastic Differential Equations}}},
  author = {Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P. and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  date = {2020},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2011.13456},
  url = {https://arxiv.org/abs/2011.13456},
  urldate = {2023-10-30},
  abstract = {Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reverse-time SDE depends only on the time-dependent gradient field (\textbackslash aka, score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in score-based generative modeling and diffusion probabilistic modeling, allowing for new sampling procedures and new modeling capabilities. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, but additionally enables exact likelihood computation, and improved sampling efficiency. In addition, we provide a new way to solve inverse problems with score-based models, as demonstrated with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 2.99 bits/dim, and demonstrate high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model.},
  version = {2},
  keywords = {FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML),new},
  file = {/Users/luca/Documents/literature/zotero/song2020.pdf}
}

@book{strang2009,
  title = {Introduction to Linear Algebra},
  author = {Strang, Gilbert},
  date = {2009},
  edition = {4th. ed},
  publisher = {Wellesley-Cambridge Press},
  location = {Wellesley},
  isbn = {978-0-9802327-1-4},
  langid = {english},
  keywords = {in progress},
  file = {/Users/luca/Documents/literature/zotero/strang2009.pdf}
}

@book{sucar2021,
  title = {Probabilistic Graphical Models: Principles and Applications},
  shorttitle = {Probabilistic Graphical Models},
  author = {Sucar, L. Enrique},
  date = {2021},
  edition = {Second edition},
  publisher = {Springer},
  location = {Cham},
  abstract = {This fully updated new edition of a uniquely accessible textbook/reference provides a general introduction to probabilistic graphical models (PGMs) from an engineering perspective. It features new material on partially observable Markov decision processes, graphical models, and deep learning, as well as an even greater number of exercises. The book covers the fundamentals for each of the main classes of PGMs, including representation, inference and learning principles, and reviews real-world applications for each type of model. These applications are drawn from a broad range of disciplines, highlighting the many uses of Bayesian classifiers, hidden Markov models, Bayesian networks, dynamic and temporal Bayesian networks, Markov random fields, influence diagrams, and Markov decision processes. Topics and features: Presents a unified framework encompassing all of the main classes of PGMs Explores the fundamental aspects of representation, inference and learning for each technique Examines new material on partially observable Markov decision processes, and graphical models Includes a new chapter introducing deep neural networks and their relation with probabilistic graphical models Covers multidimensional Bayesian classifiers, relational graphical models, and causal models Provides substantial chapter-ending exercises, suggestions for further reading, and ideas for research or programming projects Describes classifiers such as Gaussian Naive Bayes, Circular Chain Classifiers, and Hierarchical Classifiers with Bayesian Networks Outlines the practical application of the different techniques Suggests possible course outlines for instructors This classroom-tested work is suitable as a textbook for an advanced undergraduate or a graduate course in probabilistic graphical models for students of computer science, engineering, and physics. Professionals wishing to apply probabilistic graphical models in their own field, or interested in the basis of these techniques, will also find the book to be an invaluable reference. Dr. Luis Enrique Sucar is a Senior Research Scientist at the National Institute for Astrophysics, Optics and Electronics (INAOE), Puebla, Mexico},
  isbn = {978-3-030-61943-5},
  langid = {english},
  annotation = {OCLC: 1228878871},
  file = {/Users/luca/Documents/literature/zotero/sucar2021.pdf}
}

@article{takamichi2018,
  title = {Phase Reconstruction from Amplitude Spectrograms Based on Von-{{Mises-distribution}} Deep Neural Network},
  author = {Takamichi, Shinnosuke and Saito, Yuki and Takamune, Norihiro and Kitamura, Daichi and Saruwatari, Hiroshi},
  date = {2018},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1807.03474},
  url = {https://arxiv.org/abs/1807.03474},
  urldate = {2023-06-27},
  abstract = {This paper presents a deep neural network (DNN)-based phase reconstruction from amplitude spectrograms. In audio signal and speech processing, the amplitude spectrogram is often used for processing, and the corresponding phase spectrogram is reconstructed from the amplitude spectrogram on the basis of the Griffin-Lim method. However, the Griffin-Lim method causes unnatural artifacts in synthetic speech. Addressing this problem, we introduce the von-Mises-distribution DNN for phase reconstruction. The DNN is a generative model having the von Mises distribution that can model distributions of a periodic variable such as a phase, and the model parameters of the DNN are estimated on the basis of the maximum likelihood criterion. Furthermore, we propose a group-delay loss for DNN training to make the predicted group delay close to a natural group delay. The experimental results demonstrate that 1) the trained DNN can predict group delay accurately more than phases themselves, and 2) our phase reconstruction methods achieve better speech quality than the conventional Griffin-Lim method.},
  version = {1},
  keywords = {Audio and Speech Processing (eess.AS),FOS: Electrical engineering electronic engineering information engineering,read,Sound (cs.SD)},
  file = {/Users/luca/Documents/literature/zotero/takamichi2018.pdf}
}

@article{takamichi2020,
  title = {Phase Reconstruction from Amplitude Spectrograms Based on Directional-Statistics Deep Neural Networks},
  author = {Takamichi, Shinnosuke and Saito, Yuki and Takamune, Norihiro and Kitamura, Daichi and Saruwatari, Hiroshi},
  date = {2020-04},
  journaltitle = {Signal Processing},
  shortjournal = {Signal Processing},
  volume = {169},
  pages = {107368},
  issn = {01651684},
  doi = {10.1016/j.sigpro.2019.107368},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0165168419304219},
  urldate = {2023-09-19},
  langid = {english},
  keywords = {read},
  file = {/Users/luca/Documents/literature/zotero/takamichi2020.pdf;/Users/luca/Documents/literature/zotero/takamichi22.pdf}
}

@article{tewari2023,
  title = {Diffusion with {{Forward Models}}: {{Solving Stochastic Inverse Problems Without Direct Supervision}}},
  shorttitle = {Diffusion with {{Forward Models}}},
  author = {Tewari, Ayush and Yin, Tianwei and Cazenavette, George and Rezchikov, Semon and Tenenbaum, Joshua B. and Durand, Frédo and Freeman, William T. and Sitzmann, Vincent},
  date = {2023},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2306.11719},
  url = {https://arxiv.org/abs/2306.11719},
  urldate = {2023-11-18},
  abstract = {Denoising diffusion models are a powerful type of generative models used to capture complex distributions of real-world signals. However, their applicability is limited to scenarios where training samples are readily available, which is not always the case in real-world applications. For example, in inverse graphics, the goal is to generate samples from a distribution of 3D scenes that align with a given image, but ground-truth 3D scenes are unavailable and only 2D images are accessible. To address this limitation, we propose a novel class of denoising diffusion probabilistic models that learn to sample from distributions of signals that are never directly observed. Instead, these signals are measured indirectly through a known differentiable forward model, which produces partial observations of the unknown signal. Our approach involves integrating the forward model directly into the denoising process. This integration effectively connects the generative modeling of observations with the generative modeling of the underlying signals, allowing for end-to-end training of a conditional generative model over signals. During inference, our approach enables sampling from the distribution of underlying signals that are consistent with a given partial observation. We demonstrate the effectiveness of our method on three challenging computer vision tasks. For instance, in the context of inverse graphics, our model enables direct sampling from the distribution of 3D scenes that align with a single 2D input image.},
  version = {1},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,Graphics (cs.GR),Machine Learning (cs.LG)},
  file = {/Users/luca/Documents/literature/zotero/tewari2023.pdf}
}

@inproceedings{thieling2021,
  title = {Recurrent {{Phase Reconstruction Using Estimated Phase Derivatives}} from {{Deep Neural Networks}}},
  booktitle = {{{ICASSP}} 2021 - 2021 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Thieling, Lars and Wilhelm, Daniel and Jax, Peter},
  date = {2021-06-06},
  pages = {7088--7092},
  publisher = {IEEE},
  location = {Toronto, ON, Canada},
  doi = {10.1109/ICASSP39728.2021.9413722},
  url = {https://ieeexplore.ieee.org/document/9413722/},
  urldate = {2023-06-21},
  eventtitle = {{{ICASSP}} 2021 - 2021 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  isbn = {978-1-72817-605-5},
  keywords = {read},
  file = {/Users/luca/Documents/literature/zotero/thieling2021.pdf}
}

@article{togelius2023,
  title = {Choose {{Your Weapon}}: {{Survival Strategies}} for {{Depressed AI Academics}}},
  shorttitle = {Choose {{Your Weapon}}},
  author = {Togelius, Julian and Yannakakis, Georgios N.},
  date = {2023},
  publisher = {[object Object]},
  doi = {10.48550/ARXIV.2304.06035},
  url = {https://arxiv.org/abs/2304.06035},
  urldate = {2024-03-01},
  abstract = {Are you an AI researcher at an academic institution? Are you anxious you are not coping with the current pace of AI advancements? Do you feel you have no (or very limited) access to the computational and human resources required for an AI research breakthrough? You are not alone; we feel the same way. A growing number of AI academics can no longer find the means and resources to compete at a global scale. This is a somewhat recent phenomenon, but an accelerating one, with private actors investing enormous compute resources into cutting edge AI research. Here, we discuss what you can do to stay competitive while remaining an academic. We also briefly discuss what universities and the private sector could do improve the situation, if they are so inclined. This is not an exhaustive list of strategies, and you may not agree with all of them, but it serves to start a discussion.},
  version = {2},
  keywords = {Computers and Society (cs.CY),FOS: Computer and information sciences,Neural and Evolutionary Computing (cs.NE),Other Computer Science (cs.OH),read},
  file = {/Users/luca/Documents/literature/zotero/togelius2023.pdf}
}

@article{tschandl2020,
  title = {Human–Computer Collaboration for Skin Cancer Recognition},
  author = {Tschandl, Philipp and Rinner, Christoph and Apalla, Zoe and Argenziano, Giuseppe and Codella, Noel and Halpern, Allan and Janda, Monika and Lallas, Aimilios and Longo, Caterina and Malvehy, Josep and Paoli, John and Puig, Susana and Rosendahl, Cliff and Soyer, H. Peter and Zalaudek, Iris and Kittler, Harald},
  date = {2020-08},
  journaltitle = {Nature Medicine},
  shortjournal = {Nat Med},
  volume = {26},
  number = {8},
  pages = {1229--1234},
  issn = {1078-8956, 1546-170X},
  doi = {10.1038/s41591-020-0942-0},
  url = {https://www.nature.com/articles/s41591-020-0942-0},
  urldate = {2023-10-31},
  langid = {english},
  keywords = {read,reviewed},
  file = {/Users/luca/Documents/literature/zotero/tschandl2020.pdf}
}

@book{tunstall2022,
  title = {Natural Language Processing with {{Transformers}}: Building Language Applications with {{Hugging Face}}},
  shorttitle = {Natural Language Processing with {{Transformers}}},
  author = {Tunstall, Lewis and family=Werra, given=Leandro, prefix=von, useprefix=false and Wolf, Thomas and Géron, Aurélien},
  date = {2022},
  edition = {First edition},
  publisher = {O'Reilly},
  location = {Beijing Boston Farnham Sebastopol Tokyo},
  isbn = {978-1-09-810324-8},
  langid = {english},
  pagetotal = {383},
  keywords = {in progress},
  file = {/Users/luca/Documents/literature/zotero/Tunstall et al. - 2022 - Natural language processing with Transformers bui.pdf;/Users/luca/Documents/literature/zotero/tunstall2022.pdf}
}

@unknown{unknown,
  title = {Improving the Performance of {{EEG}} Decoding Using Anchored-{{STFT}} in Conjunction with Gradient Norm Adversarial Augmentation},
  author = {Ali, Omair and Saif ur Rehman, Muhammad and Dyck, Susanne and Glasmachers, Tobias and Iossifidis, Ioannis and Klaes, Christian},
  date = {2020-11}
}

@article{vahdat2020,
  title = {{{NVAE}}: {{A Deep Hierarchical Variational Autoencoder}}},
  shorttitle = {{{NVAE}}},
  author = {Vahdat, Arash and Kautz, Jan},
  date = {2020},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2007.03898},
  url = {https://arxiv.org/abs/2007.03898},
  urldate = {2023-11-15},
  abstract = {Normalizing flows, autoregressive models, variational autoencoders (VAEs), and deep energy-based models are among competing likelihood-based frameworks for deep generative learning. Among them, VAEs have the advantage of fast and tractable sampling and easy-to-access encoding networks. However, they are currently outperformed by other models such as normalizing flows and autoregressive models. While the majority of the research in VAEs is focused on the statistical challenges, we explore the orthogonal direction of carefully designing neural architectures for hierarchical VAEs. We propose Nouveau VAE (NVAE), a deep hierarchical VAE built for image generation using depth-wise separable convolutions and batch normalization. NVAE is equipped with a residual parameterization of Normal distributions and its training is stabilized by spectral regularization. We show that NVAE achieves state-of-the-art results among non-autoregressive likelihood-based models on the MNIST, CIFAR-10, CelebA 64, and CelebA HQ datasets and it provides a strong baseline on FFHQ. For example, on CIFAR-10, NVAE pushes the state-of-the-art from 2.98 to 2.91 bits per dimension, and it produces high-quality images on CelebA HQ. To the best of our knowledge, NVAE is the first successful VAE applied to natural images as large as 256\$\textbackslash times\$256 pixels. The source code is available at https://github.com/NVlabs/NVAE .},
  version = {3},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML),new}
}

@article{vallin2023,
  title = {The {{Geometric Structure}} of {{Fully-Connected ReLU Layers}}},
  author = {Vallin, Jonatan and Larsson, Karl and Larson, Mats G.},
  date = {2023},
  publisher = {[object Object]},
  doi = {10.48550/ARXIV.2310.03482},
  url = {https://arxiv.org/abs/2310.03482},
  urldate = {2024-03-01},
  abstract = {We formalize and interpret the geometric structure of \$d\$-dimensional fully connected ReLU layers in neural networks. The parameters of a ReLU layer induce a natural partition of the input domain, such that the ReLU layer can be significantly simplified in each sector of the partition. This leads to a geometric interpretation of a ReLU layer as a projection onto a polyhedral cone followed by an affine transformation, in line with the description in [doi:10.48550/arXiv.1905.08922] for convolutional networks with ReLU activations. Further, this structure facilitates simplified expressions for preimages of the intersection between partition sectors and hyperplanes, which is useful when describing decision boundaries in a classification setting. We investigate this in detail for a feed-forward network with one hidden ReLU-layer, where we provide results on the geometric complexity of the decision boundary generated by such networks, as well as proving that modulo an affine transformation, such a network can only generate \$d\$ different decision boundaries. Finally, the effect of adding more layers to the network is discussed.},
  version = {2},
  keywords = {FOS: Computer and information sciences,Machine Learning (cs.LG)},
  file = {/Users/luca/Documents/literature/zotero/vallin2023.pdf}
}

@book{vaseghi2008,
  title = {Advanced Digital Signal Processing and Noise Reduction},
  author = {Vaseghi, Saeed V.},
  date = {2008},
  edition = {4th ed},
  publisher = {J. Wiley \& Sons},
  location = {Chichester, U.K},
  isbn = {978-0-470-75406-1},
  langid = {english},
  file = {/Users/luca/Documents/literature/zotero/vaseghi2008.pdf}
}

@article{velickovic2023,
  title = {Everything Is {{Connected}}: {{Graph Neural Networks}}},
  shorttitle = {Everything Is {{Connected}}},
  author = {Veličković, Petar},
  date = {2023},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2301.08210},
  url = {https://arxiv.org/abs/2301.08210},
  urldate = {2023-11-14},
  abstract = {In many ways, graphs are the main modality of data we receive from nature. This is due to the fact that most of the patterns we see, both in natural and artificial systems, are elegantly representable using the language of graph structures. Prominent examples include molecules (represented as graphs of atoms and bonds), social networks and transportation networks. This potential has already been seen by key scientific and industrial groups, with already-impacted application areas including traffic forecasting, drug discovery, social network analysis and recommender systems. Further, some of the most successful domains of application for machine learning in previous years -- images, text and speech processing -- can be seen as special cases of graph representation learning, and consequently there has been significant exchange of information between these areas. The main aim of this short survey is to enable the reader to assimilate the key concepts in the area, and position graph representation learning in a proper context with related fields.},
  version = {1},
  keywords = {Artificial Intelligence (cs.AI),FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML),Social and Information Networks (cs.SI)},
  file = {/Users/luca/Documents/literature/zotero/velickovic2023.pdf}
}

@article{wang2021,
  title = {Deep {{High-Resolution Representation Learning}} for {{Visual Recognition}}},
  author = {Wang, Jingdong and Sun, Ke and Cheng, Tianheng and Jiang, Borui and Deng, Chaorui and Zhao, Yang and Liu, Dong and Mu, Yadong and Tan, Mingkui and Wang, Xinggang and Liu, Wenyu and Xiao, Bin},
  date = {2021-10-01},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  shortjournal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {43},
  number = {10},
  pages = {3349--3364},
  issn = {0162-8828, 2160-9292, 1939-3539},
  doi = {10.1109/TPAMI.2020.2983686},
  url = {https://ieeexplore.ieee.org/document/9052469/},
  urldate = {2023-11-30},
  keywords = {new},
  file = {/Users/luca/Documents/literature/zotero/wang2021.pdf;/Users/luca/Documents/literature/zotero/wang22.pdf}
}

@article{yegnanarayana1992,
  title = {Significance of Group Delay Functions in Spectrum Estimation},
  author = {Yegnanarayana, B. and Murthy, H.A.},
  year = {Sept./1992},
  journaltitle = {IEEE Transactions on Signal Processing},
  shortjournal = {IEEE Trans. Signal Process.},
  volume = {40},
  number = {9},
  pages = {2281--2289},
  issn = {1053587X},
  doi = {10.1109/78.157227},
  url = {http://ieeexplore.ieee.org/document/157227/},
  urldate = {2023-09-30},
  keywords = {read}
}

@article{zhang2018,
  title = {The {{Unreasonable Effectiveness}} of {{Deep Features}} as a {{Perceptual Metric}}},
  author = {Zhang, Richard and Isola, Phillip and Efros, Alexei A. and Shechtman, Eli and Wang, Oliver},
  date = {2018},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1801.03924},
  url = {https://arxiv.org/abs/1801.03924},
  urldate = {2023-09-19},
  abstract = {While it is nearly effortless for humans to quickly assess the perceptual similarity between two images, the underlying processes are thought to be quite complex. Despite this, the most widely used perceptual metrics today, such as PSNR and SSIM, are simple, shallow functions, and fail to account for many nuances of human perception. Recently, the deep learning community has found that features of the VGG network trained on ImageNet classification has been remarkably useful as a training loss for image synthesis. But how perceptual are these so-called "perceptual losses"? What elements are critical for their success? To answer these questions, we introduce a new dataset of human perceptual similarity judgments. We systematically evaluate deep features across different architectures and tasks and compare them with classic metrics. We find that deep features outperform all previous metrics by large margins on our dataset. More surprisingly, this result is not restricted to ImageNet-trained VGG features, but holds across different deep architectures and levels of supervision (supervised, self-supervised, or even unsupervised). Our results suggest that perceptual similarity is an emergent property shared across deep visual representations.},
  version = {2},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,Graphics (cs.GR)},
  file = {/Users/luca/Documents/literature/zotero/zhang2018.pdf}
}

@article{zhang2023,
  title = {Adding {{Conditional Control}} to {{Text-to-Image Diffusion Models}}},
  author = {Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
  date = {2023},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2302.05543},
  url = {https://arxiv.org/abs/2302.05543},
  urldate = {2023-11-18},
  abstract = {We present ControlNet, a neural network architecture to add spatial conditioning controls to large, pretrained text-to-image diffusion models. ControlNet locks the production-ready large diffusion models, and reuses their deep and robust encoding layers pretrained with billions of images as a strong backbone to learn a diverse set of conditional controls. The neural architecture is connected with "zero convolutions" (zero-initialized convolution layers) that progressively grow the parameters from zero and ensure that no harmful noise could affect the finetuning. We test various conditioning controls, eg, edges, depth, segmentation, human pose, etc, with Stable Diffusion, using single or multiple conditions, with or without prompts. We show that the training of ControlNets is robust with small (\&lt;50k) and large (\&gt;1m) datasets. Extensive results show that ControlNet may facilitate wider applications to control image diffusion models.},
  version = {2},
  keywords = {Artificial Intelligence (cs.AI),Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,Graphics (cs.GR),Human-Computer Interaction (cs.HC),Multimedia (cs.MM)},
  file = {/Users/luca/Documents/literature/zotero/zhang2023.pdf}
}

@article{ziyin2020,
  title = {Neural {{Networks Fail}} to {{Learn Periodic Functions}} and {{How}} to {{Fix It}}},
  author = {Ziyin, Liu and Hartwig, Tilman and Ueda, Masahito},
  date = {2020},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2006.08195},
  url = {https://arxiv.org/abs/2006.08195},
  urldate = {2023-08-27},
  abstract = {Previous literature offers limited clues on how to learn a periodic function using modern neural networks. We start with a study of the extrapolation properties of neural networks; we prove and demonstrate experimentally that the standard activations functions, such as ReLU, tanh, sigmoid, along with their variants, all fail to learn to extrapolate simple periodic functions. We hypothesize that this is due to their lack of a "periodic" inductive bias. As a fix of this problem, we propose a new activation, namely, \$x + \textbackslash sin\textasciicircum 2(x)\$, which achieves the desired periodic inductive bias to learn a periodic function while maintaining a favorable optimization property of the ReLU-based activations. Experimentally, we apply the proposed method to temperature and financial data prediction.},
  version = {2},
  keywords = {in progress,Machine Learning (cs.LG),Machine Learning (stat.ML)},
  file = {/Users/luca/Documents/literature/zotero/ziyin2020.pdf}
}
