---
title: Overview - 6 weeks to go
date: 06-07-2023
time: 13:07
author: Luca Trautmann
meditate:
exercise:
chess: 
---

# Topic Overview 
## Audio-preprocessing
<mark style="background: #FF5582A6;">Q: What are the correct definitions for the sample rate, n_fft, hope size, and mel spectrogram hops</mark>:

> Answer:

<mark style="background: #FF5582A6;">Q: What is the correct sample rate, hop size, and n_fft for the dataset that I have available here</mark>

> Answer:

<mark style="background: #FF5582A6;">Q: In Kierans Dissertation, an issue has been noted with the split of the dataset to have appropriate representations for the data in the training process. How do I approach this in my work? </mark>

> A:

<mark style="background: #FF5582A6;">Q: What exactly is the Short-time Fourier Transform and what is the Discrete Fourier Transform?</mark>

> A:


<mark style="background: #FF5582A6;">Q: What is Group delay exactly?</mark>

> A:

<mark style="background: #FF5582A6;">Q: What is Instant Frequency exactly?</mark>

> A:

<mark style="background: #FF5582A6;">Q: How do I create both (GD and IF) spectrograms with Librosa or PyTorch? </mark>

> A:


## Generative Architecture
<mark style="background: #FF5582A6;">Q: How does the formula for the mean squared error change if the variance is not constant but is also learned in the training process?</mark>

> A:

<mark style="background: #FF5582A6;">Q: How is this then implemented in PyTorch? Is there a function or does it require for the loss function to be written by me?</mark>

> A:

Q: How do I construct a GAN that takes in one image and returns two images? Do I do this with more channels or with a larger output tensor size?

> A: 


