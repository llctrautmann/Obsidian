---
title: "A review of uncertainty quantification in deep learning: Techniques, applications and challenges"
authors: Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li Liu, Mohammad Ghavamzadeh, Paul Fieguth, Xiaochun Cao, Abbas Khosravi, U. Rajendra Acharya, Vladimir Makarenkov, Saeid Nahavandi
year: 2021
DOI: 10.1016/j.inffus.2021.05.008
Tags: []
Docstring: []
modified: 2024-05-09
---
>[!Link]+
> File: [PDF](abdar2021.pdf)
> Zotero: [Zotero](zotero://select/items/@abdar2021)

# Thoughts / Relations
- This definitely relates to [[Bayes Theorem]]. 

# Annotations
> [!PDF|yellow] [[abdar2021.pdf#page=2&selection=178,4,179,68&color=yellow|abdar2021, p.2]]
> >  it is increasingly important to evaluate the reliability and efficacy of artificial intelligence (AI) systems before they could be applied

> [!PDF|yellow] [[abdar2021.pdf#page=3&selection=12,0,23,15&color=yellow|abdar2021, p.3]]
> > The irreducible uncertainty in data that gives rise to uncertainty in predictions is aleatoric uncertainty (also known as data uncertainty). This type of uncertainty is not a property of the model, but rather is an inherent property of the data distribution, and hence, it is irreducible. In contrast, epistemic uncertainty (also known as knowledge uncertainty) occurs due to inadequate knowledge. One can define models to answer different questions in model-based prediction. For data-rich problems, there may be massive collections of data that are information poor [9]. In such cases, AI-based methods can be used to define the efficient models that characterize the emergent features of the data. Very often, the data in hand are incomplete, noisy, discordant or multimodal [2].

> [!PDF|yellow] [[abdar2021.pdf#page=5&selection=467,63,469,41&color=yellow|abdar2021, p.5]]
> >  [[Dropout VI]] is one of the most common approaches and has been widely used to approximate inference in complex model

