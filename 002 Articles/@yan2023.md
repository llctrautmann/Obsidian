---
author: 
tags: 
Docstring: 
url: 
year: 
date:
  - 22-05-2024
time: 12:59
type: Paper
modified: 2024-05-22
---
# Annotation
> ([[yan2023.pdf#page=1&selection=61,18,75,50|yan2023, p.1]])
> AI models predominantly using imaging data alone can frequently exhibit limitations in their stability, generalizability and interpretability, with potential performance biases, artifacts, and even critical errors.5,6 This becomes especially evident in imaging studies for high-risk patients. For instance, individuals undergoing lung cancer screening are often predisposed to a significant cardiovascular disease risk, inadvertently inflating the perceived effectiveness of the AI model by capitalizing on the existing high-risk status of the study population.

`We should look more into multimodal models for risk determination in patients.` 

> ([[yan2023.pdf#page=1&selection=85,7,95,10&color=yellow|yan2023, p.1]])
> integrating all clinical data including radiological images, it offers the best opportunity to develop a comprehensive and multi-faceted risk prediction model that more accurately and reliably reflects the intricate nature of disease risks. It is essential to recognize that the exclusive use of imaging data may not entirely capture the breadth of risk factors. Integrating a range of data types can reduce reliance on a single modality, and hence, provide a more holistic, comprehensive, and unbiased insight into the patient's health condition.

# Summary
