---
author: 
tags: 
Docstring: 
url: 
year: 
date:
  - 22-05-2024
time: 12:59
type: Paper
modified: 2024-05-22
---
# Take-away ðŸ¥¡
- Multimodel models with integrated input might be a nice niche for a paper. 
- 
# Annotation
> ([[yan2023.pdf#page=1&selection=61,18,75,50|yan2023, p.1]])
> AI models predominantly using imaging data alone can frequently exhibit limitations in their stability, generalizability and interpretability, with potential performance biases, artifacts, and even critical errors.5,6 This becomes especially evident in imaging studies for high-risk patients. For instance, individuals undergoing lung cancer screening are often predisposed to a significant cardiovascular disease risk, inadvertently inflating the perceived effectiveness of the AI model by capitalizing on the existing high-risk status of the study population.

`We should look more into multimodal models for risk determination in patients.` 

> ([[yan2023.pdf#page=1&selection=85,7,95,10&color=yellow|yan2023, p.1]])
> integrating all clinical data including radiological images, it offers the best opportunity to develop a comprehensive and multi-faceted risk prediction model that more accurately and reliably reflects the intricate nature of disease risks. It is essential to recognize that the exclusive use of imaging data may not entirely capture the breadth of risk factors. Integrating a range of data types can reduce reliance on a single modality, and hence, provide a more holistic, comprehensive, and unbiased insight into the patient's health condition.

> [!PDF|red] [[yan2023.pdf#page=2&selection=4,39,16,50&color=red|yan2023, p.2]]
> >  [[@huang2020.pdf]] compared various multimodal fusion model architectures capable of using pixel data from volumetric CT pulmonary angiograms alongside clinical patient data from EMRs. These models were designed to automatically detect the presence of pulmonary embolism. Notably, the best-performing multimodality model was a late fusion model, which achieved an AUROC of 0.947 [95% CI: 0.946â€“0.948] on the held-out test set, surpassing the performance of models that used either imaging or EMR data alone.

GPT: [[@huang2020.pdf]] evaluated multimodal fusion models combining CT pulmonary angiogram pixel data and EMR clinical data for pulmonary embolism detection, finding that a late fusion model achieved the highest AUROC of 0.947, outperforming single-modality models.

Noteworthy: `I would like to know if we could use these types of models for better super-resolution models. Lets assume we have more `

